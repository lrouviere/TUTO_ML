<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 3 Arbres | Machine learning</title>
  <meta name="description" content="Chapitre 3 Arbres | Machine learning" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 3 Arbres | Machine learning" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 3 Arbres | Machine learning" />
  
  
  

<meta name="author" content="Laurent Rouvière" />


<meta name="date" content="2021-03-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lda.html"/>
<link rel="next" href="SVM.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning<br> <br> L. Rouvière</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Présentation</a></li>
<li class="part"><span><b>I Algorithmes de référence</b></span></li>
<li class="chapter" data-level="1" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>1</b> Estimation du risque avec caret</a>
<ul>
<li class="chapter" data-level="1.1" data-path="caret.html"><a href="caret.html#notion-de-risque-en-apprentissage-supervisé"><i class="fa fa-check"></i><b>1.1</b> Notion de risque en apprentissage supervisé</a></li>
<li class="chapter" data-level="1.2" data-path="caret.html"><a href="caret.html#la-validation-croisée"><i class="fa fa-check"></i><b>1.2</b> La validation croisée</a></li>
<li class="chapter" data-level="1.3" data-path="caret.html"><a href="caret.html#le-package-caret"><i class="fa fa-check"></i><b>1.3</b> Le package caret</a></li>
<li class="chapter" data-level="1.4" data-path="caret.html"><a href="caret.html#la-courbe-roc"><i class="fa fa-check"></i><b>1.4</b> La courbe ROC</a></li>
<li class="chapter" data-level="1.5" data-path="caret.html"><a href="caret.html#compléments"><i class="fa fa-check"></i><b>1.5</b> Compléments</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="caret.html"><a href="caret.html#calcul-parallèle"><i class="fa fa-check"></i><b>1.5.1</b> Calcul parallèle</a></li>
<li class="chapter" data-level="1.5.2" data-path="caret.html"><a href="caret.html#répéter-les-méthodes-de-rééchantillonnage"><i class="fa fa-check"></i><b>1.5.2</b> Répéter les méthodes de rééchantillonnage</a></li>
<li class="chapter" data-level="1.5.3" data-path="caret.html"><a href="caret.html#modifier-le-risque"><i class="fa fa-check"></i><b>1.5.3</b> Modifier le risque</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lda.html"><a href="lda.html"><i class="fa fa-check"></i><b>2</b> Analyse discriminante linéaire</a>
<ul>
<li class="chapter" data-level="2.1" data-path="lda.html"><a href="lda.html#prise-en-main-lda-et-qda-sur-les-iris-de-fisher"><i class="fa fa-check"></i><b>2.1</b> Prise en main : LDA et QDA sur les iris de Fisher</a></li>
<li class="chapter" data-level="2.2" data-path="lda.html"><a href="lda.html#un-cas-avec-beaucoup-de-classes"><i class="fa fa-check"></i><b>2.2</b> Un cas avec beaucoup de classes</a></li>
<li class="chapter" data-level="2.3" data-path="lda.html"><a href="lda.html#grande-dimension-reconnaissance-de-phonèmes"><i class="fa fa-check"></i><b>2.3</b> Grande dimension : reconnaissance de phonèmes</a></li>
<li class="chapter" data-level="2.4" data-path="lda.html"><a href="lda.html#exercices"><i class="fa fa-check"></i><b>2.4</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arbres.html"><a href="arbres.html"><i class="fa fa-check"></i><b>3</b> Arbres</a>
<ul>
<li class="chapter" data-level="3.1" data-path="arbres.html"><a href="arbres.html#coupures-cart-en-fonction-de-la-nature-des-variables"><i class="fa fa-check"></i><b>3.1</b> Coupures CART en fonction de la nature des variables</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="arbres.html"><a href="arbres.html#arbres-de-régression"><i class="fa fa-check"></i><b>3.1.1</b> Arbres de régression</a></li>
<li class="chapter" data-level="3.1.2" data-path="arbres.html"><a href="arbres.html#arbres-de-classification"><i class="fa fa-check"></i><b>3.1.2</b> Arbres de classification</a></li>
<li class="chapter" data-level="3.1.3" data-path="arbres.html"><a href="arbres.html#entrée-qualitative"><i class="fa fa-check"></i><b>3.1.3</b> Entrée qualitative</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="arbres.html"><a href="arbres.html#élagage"><i class="fa fa-check"></i><b>3.2</b> Élagage</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="arbres.html"><a href="arbres.html#élagage-pour-un-problème-de-régression"><i class="fa fa-check"></i><b>3.2.1</b> Élagage pour un problème de régression</a></li>
<li class="chapter" data-level="3.2.2" data-path="arbres.html"><a href="arbres.html#élagage-en-classification-binaire-et-matrice-de-coût"><i class="fa fa-check"></i><b>3.2.2</b> Élagage en classification binaire et matrice de coût</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Algorithmes avancés</b></span></li>
<li class="chapter" data-level="4" data-path="SVM.html"><a href="SVM.html"><i class="fa fa-check"></i><b>4</b> Support Vector Machine (SVM)</a>
<ul>
<li class="chapter" data-level="4.1" data-path="SVM.html"><a href="SVM.html#cas-séparable"><i class="fa fa-check"></i><b>4.1</b> Cas séparable</a></li>
<li class="chapter" data-level="4.2" data-path="SVM.html"><a href="SVM.html#cas-non-séparable"><i class="fa fa-check"></i><b>4.2</b> Cas non séparable</a></li>
<li class="chapter" data-level="4.3" data-path="SVM.html"><a href="SVM.html#lastuce-du-noyau"><i class="fa fa-check"></i><b>4.3</b> L’astuce du noyau</a></li>
<li class="chapter" data-level="4.4" data-path="SVM.html"><a href="SVM.html#support-vector-régression"><i class="fa fa-check"></i><b>4.4</b> Support vector régression</a></li>
<li class="chapter" data-level="4.5" data-path="SVM.html"><a href="SVM.html#svm-sur-les-données-spam"><i class="fa fa-check"></i><b>4.5</b> SVM sur les données spam</a></li>
<li class="chapter" data-level="4.6" data-path="SVM.html"><a href="SVM.html#exercices-1"><i class="fa fa-check"></i><b>4.6</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agregation.html"><a href="agregation.html"><i class="fa fa-check"></i><b>5</b> Agrégation : forêts aléatoires et gradient boosting</a>
<ul>
<li class="chapter" data-level="5.1" data-path="agregation.html"><a href="agregation.html#forets"><i class="fa fa-check"></i><b>5.1</b> Forêts aléatoires</a></li>
<li class="chapter" data-level="5.2" data-path="agregation.html"><a href="agregation.html#boosting"><i class="fa fa-check"></i><b>5.2</b> Gradient boosting</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="agregation.html"><a href="agregation.html#un-exemple-simple-en-régression"><i class="fa fa-check"></i><b>5.2.1</b> Un exemple simple en régression</a></li>
<li class="chapter" data-level="5.2.2" data-path="agregation.html"><a href="agregation.html#adaboost-et-logitboost-pour-la-classification-binaire."><i class="fa fa-check"></i><b>5.2.2</b> Adaboost et logitboost pour la classification binaire.</a></li>
<li class="chapter" data-level="5.2.3" data-path="agregation.html"><a href="agregation.html#exo:grad-boost"><i class="fa fa-check"></i><b>5.2.3</b> Exercices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="deep.html"><a href="deep.html"><i class="fa fa-check"></i><b>6</b> Réseaux de neurones avec Keras</a></li>
<li class="chapter" data-level="7" data-path="dondes.html"><a href="dondes.html"><i class="fa fa-check"></i><b>7</b> Données déséquilibrées</a>
<ul>
<li class="chapter" data-level="7.1" data-path="dondes.html"><a href="dondes.html#critères-de-performance-pour-données-déséquilibrées"><i class="fa fa-check"></i><b>7.1</b> Critères de performance pour données déséquilibrées</a></li>
<li class="chapter" data-level="7.2" data-path="dondes.html"><a href="dondes.html#ré-équilibrage"><i class="fa fa-check"></i><b>7.2</b> Ré-équilibrage</a></li>
<li class="chapter" data-level="7.3" data-path="dondes.html"><a href="dondes.html#exercices-supplémentaires"><i class="fa fa-check"></i><b>7.3</b> Exercices supplémentaires</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="comp-algo.html"><a href="comp-algo.html"><i class="fa fa-check"></i><b>8</b> Comparaison d’algorithmes</a></li>
<li class="chapter" data-level="" data-path="références.html"><a href="références.html"><i class="fa fa-check"></i>Références</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="arbres" class="section level1" number="3">
<h1><span class="header-section-number">Chapitre 3</span> Arbres</h1>
<p>Les méthodes par arbres sont des algorithmes où la prévision s’effectue à partir de <strong>moyennes locales</strong>. Plus précisément, étant donné un échantillon <span class="math inline">\((x_1,y_1)\dots,(x_n,y_n)\)</span>, l’approche consiste à :</p>
<ul>
<li>construire une partition de l’espace de variables explicatives (<span class="math inline">\(\mathbb R^p\)</span>) ;</li>
<li>prédire la sortie d’une nouvelle observation <span class="math inline">\(x\)</span> en faisant :
<ul>
<li>la moyenne des <span class="math inline">\(y_i\)</span> pour les <span class="math inline">\(x_i\)</span> qui sont dans la même classe que <span class="math inline">\(x\)</span> si on est en régression ;</li>
<li>un vote à la majorité parmi les <span class="math inline">\(y_i\)</span> tels que les <span class="math inline">\(x_i\)</span> qui sont dans la même classe que <span class="math inline">\(x\)</span> si on est en classification.</li>
</ul></li>
</ul>
<p>Bien entendu toute la difficulté est de trouver la “bonne partition” pour le problème d’intérêt. Il existe un grand nombre d’algorithmes qui permettent de trouver une partition. Le plus connu est l’algorithme <strong>CART</strong> <span class="citation">(<a href="références.html#ref-brfrolst84" role="doc-biblioref">Breiman et al. 1984</a>)</span> où la partition est construite par <strong>divisions successives</strong> au moyen d’hyperplan orthogonaux aux axes de <span class="math inline">\(\mathbb R^p\)</span>. L’algorithme est récursif : il va à chaque étape séparer un groupe d’observations (<strong>nœuds</strong>) en deux groupes (<strong>nœuds fils</strong>) en cherchant la meilleure variable et le meilleur seuil de coupure. Ce choix s’effectue à partir d’un critère <strong>d’impureté</strong> : la meilleure coupure est celle pour laquelle l’impureté des 2 nœuds fils sera minimale. Nous étudions cet algorithme dans cette partie.</p>
<div id="coupures-cart-en-fonction-de-la-nature-des-variables" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Coupures CART en fonction de la nature des variables</h2>
<p>Une partition CART s’obtient en séparant les observations en 2 selon une coupure parallèle aux axes puis en itérant ce procédé de séparation binaire sur les deux groupes… Par conséquent la première question à se poser est : pour un ensemble de données <span class="math inline">\((x_1,y_1),\dots,(x_n,y_n)\)</span> fixé, comment obtenir la meilleure coupure ?</p>
<p>Comme souvent ce sont les données qui vont répondre à cette question. La sélection de la meilleur coupure s’effectue en introduisant une <strong>fonction d’impureté <span class="math inline">\(\mathcal I\)</span></strong> qui va mesurer le degrés d’hétérogénéité d’un nœud <span class="math inline">\(\mathcal N\)</span>. Cette fonction prendra de</p>
<ul>
<li>grandes valeurs pour les nœuds hétérogènes (les valeurs de <span class="math inline">\(Y\)</span> diffèrent à l’intérieur du nœud) ;</li>
<li>faibles valeurs pour les nœuds homogènes (les valeurs de <span class="math inline">\(Y\)</span> sont proches à l’intérieur du nœud).</li>
</ul>
<p>On utilise souvent comme fonction d’impureté :</p>
<ul>
<li>la <strong>variance</strong> en régression
<span class="math display">\[\mathcal I(\mathcal N)=\frac{1}{|\mathcal N|}\sum_{i:x_i\in\mathcal N}(y_i-\overline{y}_\mathcal N)^2,\]</span>
où <span class="math inline">\(\overline{y} _\mathcal N\)</span> désigne la moyenne des <span class="math inline">\(y_i\)</span> dans <span class="math inline">\(\mathcal N\)</span>.</li>
<li>l’impureté de <strong>Gini</strong> en classification binaire
<span class="math display">\[\mathcal I(\mathcal N)=2p(\mathcal N)(1-p(\mathcal N))\]</span>
où <span class="math inline">\(p(\mathcal N)\)</span> représente la proportion de 1 dans <span class="math inline">\(\mathcal N\)</span>.</li>
</ul>
<p>Les coupures considérées par l’algorithme CART sont des hyperplans orthogonaux aux axes de <span class="math inline">\(\mathbb R^p\)</span>, choisir une coupure revient donc à choisir une variable <span class="math inline">\(j\)</span> parmi les <span class="math inline">\(p\)</span> variables explicatives et un seuil <span class="math inline">\(s\)</span> dans <span class="math inline">\(\mathbb R\)</span>. On peut donc représenter une coupure par un couple <span class="math inline">\((j,s)\)</span>.
Une fois l’impureté définie, on choisira la coupure <span class="math inline">\((j,s)\)</span> qui <strong>maximise le gain d’impureté</strong> entre le noeud père et ses deux noeuds fils :
<span class="math display">\[\Delta(\mathcal I)=\mathbf P(\mathcal N)\mathcal I(\mathcal N)-(\mathbf P(\mathcal N_1(j,s))\mathcal I(\mathcal N_1(j,s))+\mathbf P(\mathcal N_2(j,s))\mathcal I(\mathcal N_2(j,s))\]</span>
où
* <span class="math inline">\(\mathcal N_1(j,s)\)</span> et <span class="math inline">\(\mathcal N_2(j,s)\)</span> sont les 2 nœuds fils de <span class="math inline">\(\mathcal N\)</span> engendrés par la coupure <span class="math inline">\((j,s)\)</span> ;
* <span class="math inline">\(\mathbf P(\mathcal N)\)</span> représente la proportion d’observations dans le nœud <span class="math inline">\(\mathcal N\)</span>.</p>
<div id="arbres-de-régression" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Arbres de régression</h3>
<p>On considère le jeu de données suivant où le problème est d’expliquer la variable quantitative <span class="math inline">\(Y\)</span> par la variable quantitative <span class="math inline">\(X\)</span>.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="arbres.html#cb74-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb74-2"><a href="arbres.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb74-3"><a href="arbres.html#cb74-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb74-4"><a href="arbres.html#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5678</span>)</span>
<span id="cb74-5"><a href="arbres.html#cb74-5" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">*</span>X<span class="sc">*</span>(X<span class="sc">&lt;=</span><span class="fl">0.6</span>)<span class="sc">+</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">*</span>X<span class="fl">+3.2</span>)<span class="sc">*</span>(X<span class="sc">&gt;</span><span class="fl">0.6</span>)<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="at">sd=</span><span class="fl">0.1</span>)</span>
<span id="cb74-6"><a href="arbres.html#cb74-6" aria-hidden="true" tabindex="-1"></a>data1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(X,Y)</span>
<span id="cb74-7"><a href="arbres.html#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data1)<span class="sc">+</span><span class="fu">aes</span>(<span class="at">x=</span>X,<span class="at">y=</span>Y)<span class="sc">+</span><span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-135-1.png" width="672" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: decimal">
<li><p>A l’aide de la fonction <strong>rpart</strong> du package <strong>rpart</strong>, construire un arbre permettant d’expliquer <span class="math inline">\(Y\)</span> par <span class="math inline">\(X\)</span>.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="arbres.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span></code></pre></div></li>
<li><p>Visualiser l’arbre à l’aide des fonctions <strong>prp</strong> et <strong>rpart.plot</strong> du package <strong>rpart.plot</strong>.</p></li>
<li><p>Écrire l’estimateur associé à l’arbre.</p></li>
<li><p>Ajouter sur le graphe de la question 1 la partition définie par l’arbre ainsi que les valeurs prédites.</p></li>
</ol>
</div>
<div id="arbres-de-classification" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Arbres de classification</h3>
<p>On considère les données suivantes où le problème est d’expliquer la variable binaire <span class="math inline">\(Y\)</span> par deux variables quantitatives <span class="math inline">\(X_1\)</span> et <span class="math inline">\(X_2\)</span>.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="arbres.html#cb76-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb76-2"><a href="arbres.html#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb76-3"><a href="arbres.html#cb76-3" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb76-4"><a href="arbres.html#cb76-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5678</span>)</span>
<span id="cb76-5"><a href="arbres.html#cb76-5" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb76-6"><a href="arbres.html#cb76-6" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,n)</span>
<span id="cb76-7"><a href="arbres.html#cb76-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">54321</span>)</span>
<span id="cb76-8"><a href="arbres.html#cb76-8" aria-hidden="true" tabindex="-1"></a>Y[X1<span class="sc">&lt;=</span><span class="fl">0.45</span>] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(X1<span class="sc">&lt;=</span><span class="fl">0.45</span>),<span class="dv">1</span>,<span class="fl">0.85</span>)</span>
<span id="cb76-9"><a href="arbres.html#cb76-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">52432</span>)</span>
<span id="cb76-10"><a href="arbres.html#cb76-10" aria-hidden="true" tabindex="-1"></a>Y[X1<span class="sc">&gt;</span><span class="fl">0.45</span>] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(X1<span class="sc">&gt;</span><span class="fl">0.45</span>),<span class="dv">1</span>,<span class="fl">0.15</span>)</span>
<span id="cb76-11"><a href="arbres.html#cb76-11" aria-hidden="true" tabindex="-1"></a>data2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(X1,X2,Y)</span>
<span id="cb76-12"><a href="arbres.html#cb76-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data2)<span class="sc">+</span><span class="fu">aes</span>(<span class="at">x=</span>X1,<span class="at">y=</span>X2,<span class="at">color=</span>Y)<span class="sc">+</span><span class="fu">geom_point</span>(<span class="at">size=</span><span class="dv">2</span>)<span class="sc">+</span><span class="fu">scale_x_continuous</span>(<span class="at">name=</span><span class="st">&quot;&quot;</span>)<span class="sc">+</span></span>
<span id="cb76-13"><a href="arbres.html#cb76-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">name=</span><span class="st">&quot;&quot;</span>)<span class="sc">+</span><span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-142-1.png" width="672" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: decimal">
<li><p>Construire un arbre permettant d’expliquer <span class="math inline">\(Y\)</span> par <span class="math inline">\(X_1\)</span> et <span class="math inline">\(X_2\)</span>. Représenter l’arbre et identifier l’éventuel problème.</p></li>
<li><p>Écrire la règle de classification ainsi que la fonction de score définies par l’arbre.</p></li>
<li><p>Ajouter sur le graphe de la question 1 la partition définie par l’arbre.</p></li>
</ol>
</div>
<div id="entrée-qualitative" class="section level3" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Entrée qualitative</h3>
<p>On considère les données</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="arbres.html#cb77-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb77-2"><a href="arbres.html#cb77-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;A&quot;</span>,<span class="st">&quot;B&quot;</span>,<span class="st">&quot;C&quot;</span>,<span class="st">&quot;D&quot;</span>),n))</span>
<span id="cb77-3"><a href="arbres.html#cb77-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb77-4"><a href="arbres.html#cb77-4" aria-hidden="true" tabindex="-1"></a>Y[X<span class="sc">==</span><span class="st">&quot;A&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(X<span class="sc">==</span><span class="st">&quot;A&quot;</span>),<span class="dv">1</span>,<span class="fl">0.9</span>)</span>
<span id="cb77-5"><a href="arbres.html#cb77-5" aria-hidden="true" tabindex="-1"></a>Y[X<span class="sc">==</span><span class="st">&quot;B&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(X<span class="sc">==</span><span class="st">&quot;B&quot;</span>),<span class="dv">1</span>,<span class="fl">0.25</span>)</span>
<span id="cb77-6"><a href="arbres.html#cb77-6" aria-hidden="true" tabindex="-1"></a>Y[X<span class="sc">==</span><span class="st">&quot;C&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(X<span class="sc">==</span><span class="st">&quot;C&quot;</span>),<span class="dv">1</span>,<span class="fl">0.8</span>)</span>
<span id="cb77-7"><a href="arbres.html#cb77-7" aria-hidden="true" tabindex="-1"></a>Y[X<span class="sc">==</span><span class="st">&quot;D&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(X<span class="sc">==</span><span class="st">&quot;D&quot;</span>),<span class="dv">1</span>,<span class="fl">0.2</span>)</span>
<span id="cb77-8"><a href="arbres.html#cb77-8" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(Y)</span>
<span id="cb77-9"><a href="arbres.html#cb77-9" aria-hidden="true" tabindex="-1"></a>data3 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(X,Y)</span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>Construire un arbre permettant d’expliquer <span class="math inline">\(Y\)</span> par <span class="math inline">\(X\)</span>.</p></li>
<li><p>Expliquer la manière dont l’arbre est construit dans ce cadre là.</p></li>
</ol>
</div>
</div>
<div id="élagage" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Élagage</h2>
<p>Le procédé de coupe présenté précédemment permet de définir un très grand nombre d’arbres à partir d’un jeu de données (arbre sans coupure, avec une coupure, deux coupures…). Se pose alors la question de trouver le <strong>meilleur arbre</strong> parmi tous les arbres possibles. Une première idée serait de choisir parmi tous les arbres possibles celui qui optimise un critère de performance. Cette approche, bien que cohérente, n’est généralement pas possible à mettre en œuvre en pratique car le nombre d’arbres à considérer est souvent trop important.</p>
<p>La méthode CART propose une procédure permettant de choisir automatiquement un arbre en 3 étapes :</p>
<ul>
<li>On construit un <strong>arbre maximal</strong> (très profond) <span class="math inline">\(\mathcal T_{max}\)</span> ;</li>
<li>On sélectionne une <strong>suite d’arbres emboités</strong> :
<span class="math display">\[\mathcal T_{max}=\mathcal T_0\supset\mathcal T_1\supset\dots\supset \mathcal T_K.\]</span>
La sélection s’effectue en optimisant un critère <strong>Cout/complexité</strong> qui permet de réguler le compromis entre <strong>ajustement</strong> et <strong>complexité</strong> de l’arbre.</li>
<li>On <strong>sélectionne un arbre</strong> dans cette sous-suite en optimisant un critère de performance.</li>
</ul>
<p>Cette approche revient à choisir un sous-arbre de l’arbre <span class="math inline">\(\mathcal T_\text{max}\)</span>, c’est-à-dire à enlever des branches à <span class="math inline">\(T_\text{max}\)</span>, c’est pourquoi on parle <strong>d’élagage</strong>.</p>
<div id="élagage-pour-un-problème-de-régression" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Élagage pour un problème de régression</h3>
<p>On considère les données <strong>Carseats</strong> du package <strong>ISLR</strong>.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="arbres.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb78-2"><a href="arbres.html#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Carseats)</span>
<span id="cb78-3"><a href="arbres.html#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Carseats)</span>
<span id="cb78-4"><a href="arbres.html#cb78-4" aria-hidden="true" tabindex="-1"></a>     Sales          CompPrice       Income      </span>
<span id="cb78-5"><a href="arbres.html#cb78-5" aria-hidden="true" tabindex="-1"></a> Min.   <span class="sc">:</span> <span class="fl">0.000</span>   Min.   <span class="sc">:</span> <span class="dv">77</span>   Min.   <span class="sc">:</span> <span class="fl">21.00</span>  </span>
<span id="cb78-6"><a href="arbres.html#cb78-6" aria-hidden="true" tabindex="-1"></a> 1st Qu.<span class="sc">:</span> <span class="fl">5.390</span>   1st Qu.<span class="sc">:</span><span class="dv">115</span>   1st Qu.<span class="sc">:</span> <span class="fl">42.75</span>  </span>
<span id="cb78-7"><a href="arbres.html#cb78-7" aria-hidden="true" tabindex="-1"></a> Median <span class="sc">:</span> <span class="fl">7.490</span>   Median <span class="sc">:</span><span class="dv">125</span>   Median <span class="sc">:</span> <span class="fl">69.00</span>  </span>
<span id="cb78-8"><a href="arbres.html#cb78-8" aria-hidden="true" tabindex="-1"></a> Mean   <span class="sc">:</span> <span class="fl">7.496</span>   Mean   <span class="sc">:</span><span class="dv">125</span>   Mean   <span class="sc">:</span> <span class="fl">68.66</span>  </span>
<span id="cb78-9"><a href="arbres.html#cb78-9" aria-hidden="true" tabindex="-1"></a> 3rd Qu.<span class="sc">:</span> <span class="fl">9.320</span>   3rd Qu.<span class="sc">:</span><span class="dv">135</span>   3rd Qu.<span class="sc">:</span> <span class="fl">91.00</span>  </span>
<span id="cb78-10"><a href="arbres.html#cb78-10" aria-hidden="true" tabindex="-1"></a> Max.   <span class="sc">:</span><span class="fl">16.270</span>   Max.   <span class="sc">:</span><span class="dv">175</span>   Max.   <span class="sc">:</span><span class="fl">120.00</span>  </span>
<span id="cb78-11"><a href="arbres.html#cb78-11" aria-hidden="true" tabindex="-1"></a>  Advertising       Population        Price      </span>
<span id="cb78-12"><a href="arbres.html#cb78-12" aria-hidden="true" tabindex="-1"></a> Min.   <span class="sc">:</span> <span class="fl">0.000</span>   Min.   <span class="sc">:</span> <span class="fl">10.0</span>   Min.   <span class="sc">:</span> <span class="fl">24.0</span>  </span>
<span id="cb78-13"><a href="arbres.html#cb78-13" aria-hidden="true" tabindex="-1"></a> 1st Qu.<span class="sc">:</span> <span class="fl">0.000</span>   1st Qu.<span class="sc">:</span><span class="fl">139.0</span>   1st Qu.<span class="sc">:</span><span class="fl">100.0</span>  </span>
<span id="cb78-14"><a href="arbres.html#cb78-14" aria-hidden="true" tabindex="-1"></a> Median <span class="sc">:</span> <span class="fl">5.000</span>   Median <span class="sc">:</span><span class="fl">272.0</span>   Median <span class="sc">:</span><span class="fl">117.0</span>  </span>
<span id="cb78-15"><a href="arbres.html#cb78-15" aria-hidden="true" tabindex="-1"></a> Mean   <span class="sc">:</span> <span class="fl">6.635</span>   Mean   <span class="sc">:</span><span class="fl">264.8</span>   Mean   <span class="sc">:</span><span class="fl">115.8</span>  </span>
<span id="cb78-16"><a href="arbres.html#cb78-16" aria-hidden="true" tabindex="-1"></a> 3rd Qu.<span class="sc">:</span><span class="fl">12.000</span>   3rd Qu.<span class="sc">:</span><span class="fl">398.5</span>   3rd Qu.<span class="sc">:</span><span class="fl">131.0</span>  </span>
<span id="cb78-17"><a href="arbres.html#cb78-17" aria-hidden="true" tabindex="-1"></a> Max.   <span class="sc">:</span><span class="fl">29.000</span>   Max.   <span class="sc">:</span><span class="fl">509.0</span>   Max.   <span class="sc">:</span><span class="fl">191.0</span>  </span>
<span id="cb78-18"><a href="arbres.html#cb78-18" aria-hidden="true" tabindex="-1"></a>  ShelveLoc        Age          Education    Urban    </span>
<span id="cb78-19"><a href="arbres.html#cb78-19" aria-hidden="true" tabindex="-1"></a> Bad   <span class="sc">:</span> <span class="dv">96</span>   Min.   <span class="sc">:</span><span class="fl">25.00</span>   Min.   <span class="sc">:</span><span class="fl">10.0</span>   No <span class="sc">:</span><span class="dv">118</span>  </span>
<span id="cb78-20"><a href="arbres.html#cb78-20" aria-hidden="true" tabindex="-1"></a> Good  <span class="sc">:</span> <span class="dv">85</span>   1st Qu.<span class="sc">:</span><span class="fl">39.75</span>   1st Qu.<span class="sc">:</span><span class="fl">12.0</span>   Yes<span class="sc">:</span><span class="dv">282</span>  </span>
<span id="cb78-21"><a href="arbres.html#cb78-21" aria-hidden="true" tabindex="-1"></a> Medium<span class="sc">:</span><span class="dv">219</span>   Median <span class="sc">:</span><span class="fl">54.50</span>   Median <span class="sc">:</span><span class="fl">14.0</span>            </span>
<span id="cb78-22"><a href="arbres.html#cb78-22" aria-hidden="true" tabindex="-1"></a>              Mean   <span class="sc">:</span><span class="fl">53.32</span>   Mean   <span class="sc">:</span><span class="fl">13.9</span>            </span>
<span id="cb78-23"><a href="arbres.html#cb78-23" aria-hidden="true" tabindex="-1"></a>              3rd Qu.<span class="sc">:</span><span class="fl">66.00</span>   3rd Qu.<span class="sc">:</span><span class="fl">16.0</span>            </span>
<span id="cb78-24"><a href="arbres.html#cb78-24" aria-hidden="true" tabindex="-1"></a>              Max.   <span class="sc">:</span><span class="fl">80.00</span>   Max.   <span class="sc">:</span><span class="fl">18.0</span>            </span>
<span id="cb78-25"><a href="arbres.html#cb78-25" aria-hidden="true" tabindex="-1"></a>   US     </span>
<span id="cb78-26"><a href="arbres.html#cb78-26" aria-hidden="true" tabindex="-1"></a> No <span class="sc">:</span><span class="dv">142</span>  </span>
<span id="cb78-27"><a href="arbres.html#cb78-27" aria-hidden="true" tabindex="-1"></a> Yes<span class="sc">:</span><span class="dv">258</span>  </span>
<span id="cb78-28"><a href="arbres.html#cb78-28" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb78-29"><a href="arbres.html#cb78-29" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb78-30"><a href="arbres.html#cb78-30" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb78-31"><a href="arbres.html#cb78-31" aria-hidden="true" tabindex="-1"></a>          </span></code></pre></div>
<p>On cherche ici à expliquer la variable quantitative <strong>Sales</strong> par les autres variables.</p>
<ol style="list-style-type: decimal">
<li><p>Construire un arbre permettant de répondre au problème.</p></li>
<li><p>Expliquer les sorties de la fonction <strong>printcp</strong> appliquée à l’arbre de la question précédente et calculer le dernier terme de la colonne <strong>rel error</strong>.</p></li>
<li><p>Construire une suite d’arbres plus grandes en jouant sur les paramètres <code>cp</code> et <code>minsplit</code> de la fonction <strong>rpart</strong>.</p></li>
<li><p>Expliquer la sortie de la fonction <strong>plotcp</strong> appliquée à l’arbre de la question précédente.</p></li>
<li><p>Sélectionner le “meilleur” arbre dans la suite construite.</p></li>
<li><p>Visualiser l’arbre choisi (utiliser la fonction <strong>prune</strong>).</p></li>
<li><p>On souhaite prédire les valeurs de <span class="math inline">\(Y\)</span> pour de nouveaux individus à partir de l’arbre sélectionné. Pour simplifier on considèrera ces 4 individus :</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="arbres.html#cb79-1" aria-hidden="true" tabindex="-1"></a>new_ind <span class="ot">&lt;-</span> Carseats <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="dv">3</span>,<span class="dv">58</span>,<span class="dv">185</span>,<span class="dv">218</span>) <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>Sales)</span>
<span id="cb79-2"><a href="arbres.html#cb79-2" aria-hidden="true" tabindex="-1"></a>new_ind</span>
<span id="cb79-3"><a href="arbres.html#cb79-3" aria-hidden="true" tabindex="-1"></a>    CompPrice Income Advertising Population Price ShelveLoc</span>
<span id="cb79-4"><a href="arbres.html#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>         <span class="dv">113</span>     <span class="dv">35</span>          <span class="dv">10</span>        <span class="dv">269</span>    <span class="dv">80</span>    Medium</span>
<span id="cb79-5"><a href="arbres.html#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="dv">58</span>         <span class="dv">93</span>     <span class="dv">91</span>           <span class="dv">0</span>         <span class="dv">22</span>   <span class="dv">117</span>       Bad</span>
<span id="cb79-6"><a href="arbres.html#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="dv">185</span>       <span class="dv">132</span>     <span class="dv">33</span>           <span class="dv">7</span>         <span class="dv">35</span>    <span class="dv">97</span>    Medium</span>
<span id="cb79-7"><a href="arbres.html#cb79-7" aria-hidden="true" tabindex="-1"></a><span class="dv">218</span>       <span class="dv">106</span>     <span class="dv">44</span>           <span class="dv">0</span>        <span class="dv">481</span>   <span class="dv">111</span>    Medium</span>
<span id="cb79-8"><a href="arbres.html#cb79-8" aria-hidden="true" tabindex="-1"></a>    Age Education Urban  US</span>
<span id="cb79-9"><a href="arbres.html#cb79-9" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>    <span class="dv">59</span>        <span class="dv">12</span>   Yes Yes</span>
<span id="cb79-10"><a href="arbres.html#cb79-10" aria-hidden="true" tabindex="-1"></a><span class="dv">58</span>   <span class="dv">75</span>        <span class="dv">11</span>   Yes  No</span>
<span id="cb79-11"><a href="arbres.html#cb79-11" aria-hidden="true" tabindex="-1"></a><span class="dv">185</span>  <span class="dv">60</span>        <span class="dv">11</span>    No Yes</span>
<span id="cb79-12"><a href="arbres.html#cb79-12" aria-hidden="true" tabindex="-1"></a><span class="dv">218</span>  <span class="dv">70</span>        <span class="dv">14</span>    No  No</span></code></pre></div>
<p>Calculer les valeurs prédites.</p></li>
<li><p>Séparer les données en un échantillon d’apprentissage de taille 250 et un échantillon test de taille 150.</p></li>
<li><p>On considère la suite d’arbres définie par</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="arbres.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4321</span>)</span>
<span id="cb80-2"><a href="arbres.html#cb80-2" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Sales<span class="sc">~</span>.,<span class="at">data=</span>train,<span class="at">cp=</span><span class="fl">0.000001</span>,<span class="at">minsplit=</span><span class="dv">2</span>)</span></code></pre></div>
<p>Dans cette suite, sélectionner</p>
<ul>
<li>un arbre très simple (avec 2 ou 3 coupures)</li>
<li>un arbre très grand</li>
<li>l’arbre optimal (avec la procédure d’élagage classique).</li>
</ul></li>
<li><p>Calculer l’erreur quadratique de ces 3 arbres en utilisant l’échantillon test.</p></li>
<li><p>Refaire la comparaison avec une validation croisée 10 blocs.</p></li>
</ol>
</div>
<div id="élagage-en-classification-binaire-et-matrice-de-coût" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Élagage en classification binaire et matrice de coût</h3>
<p>On considère ici les mêmes données que précédemment mais on cherche à expliquer une version binaire de la variable <strong>Sales</strong>. Cette nouvelle variable, appelée <code>High</code> prend pour valeurs <code>No</code> si <code>Sales</code> est inférieur ou égal à 8, <code>Yes</code> sinon. On travaillera donc avec le jeu <code>data1</code> défini ci-dessous.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="arbres.html#cb81-1" aria-hidden="true" tabindex="-1"></a>High <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Carseats<span class="sc">$</span>Sales<span class="sc">&lt;=</span><span class="dv">8</span>,<span class="st">&quot;No&quot;</span>,<span class="st">&quot;Yes&quot;</span>)</span>
<span id="cb81-2"><a href="arbres.html#cb81-2" aria-hidden="true" tabindex="-1"></a>data1 <span class="ot">&lt;-</span> Carseats <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>Sales) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(High)</span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>Construire un arbre permettant d’expliquer <code>High</code> par les autres variables (sans <code>Sales</code> évidemment !) et expliquer les principales différences par rapport à la partie précédente précédente.</p></li>
<li><p>Expliquer l’option <code>parms</code> dans la commande :</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="arbres.html#cb82-1" aria-hidden="true" tabindex="-1"></a>tree1 <span class="ot">&lt;-</span> <span class="fu">rpart</span>(High<span class="sc">~</span>.,<span class="at">data=</span>data1,<span class="at">parms=</span><span class="fu">list</span>(<span class="at">split=</span><span class="st">&quot;information&quot;</span>))</span>
<span id="cb82-2"><a href="arbres.html#cb82-2" aria-hidden="true" tabindex="-1"></a>tree1<span class="sc">$</span>parms</span>
<span id="cb82-3"><a href="arbres.html#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>prior</span>
<span id="cb82-4"><a href="arbres.html#cb82-4" aria-hidden="true" tabindex="-1"></a>   <span class="dv">1</span>    <span class="dv">2</span> </span>
<span id="cb82-5"><a href="arbres.html#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="fl">0.59</span> <span class="fl">0.41</span> </span>
<span id="cb82-6"><a href="arbres.html#cb82-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-7"><a href="arbres.html#cb82-7" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>loss</span>
<span id="cb82-8"><a href="arbres.html#cb82-8" aria-hidden="true" tabindex="-1"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>]</span>
<span id="cb82-9"><a href="arbres.html#cb82-9" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>,]    <span class="dv">0</span>    <span class="dv">1</span></span>
<span id="cb82-10"><a href="arbres.html#cb82-10" aria-hidden="true" tabindex="-1"></a>[<span class="dv">2</span>,]    <span class="dv">1</span>    <span class="dv">0</span></span>
<span id="cb82-11"><a href="arbres.html#cb82-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-12"><a href="arbres.html#cb82-12" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>split</span>
<span id="cb82-13"><a href="arbres.html#cb82-13" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">2</span></span></code></pre></div></li>
<li><p>Expliquer les sorties de la fonction <strong>printcp</strong> sur le premier arbre construit et retrouver la valeur du dernier terme de la colonne <strong>rel error</strong>.</p></li>
<li><p>Sélectionner un arbre optimal dans la suite.</p></li>
<li><p>On considère la suite d’arbres</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="arbres.html#cb83-1" aria-hidden="true" tabindex="-1"></a>tree2 <span class="ot">&lt;-</span> <span class="fu">rpart</span>(High<span class="sc">~</span>.,<span class="at">data=</span>data1,<span class="at">parms=</span><span class="fu">list</span>(<span class="at">loss=</span><span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">5</span>,<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">ncol=</span><span class="dv">2</span>)),</span>
<span id="cb83-2"><a href="arbres.html#cb83-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">cp=</span><span class="fl">0.01</span>,<span class="at">minsplit=</span><span class="dv">2</span>)</span></code></pre></div>
<p>Expliquer les sorties des commandes suivantes. On pourra notamment calculer le dernier terme de la colonne <strong>rel error</strong> de la table <strong>cptable</strong>.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="arbres.html#cb84-1" aria-hidden="true" tabindex="-1"></a>tree2<span class="sc">$</span>parms</span>
<span id="cb84-2"><a href="arbres.html#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>prior</span>
<span id="cb84-3"><a href="arbres.html#cb84-3" aria-hidden="true" tabindex="-1"></a>   <span class="dv">1</span>    <span class="dv">2</span> </span>
<span id="cb84-4"><a href="arbres.html#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="fl">0.59</span> <span class="fl">0.41</span> </span>
<span id="cb84-5"><a href="arbres.html#cb84-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-6"><a href="arbres.html#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>loss</span>
<span id="cb84-7"><a href="arbres.html#cb84-7" aria-hidden="true" tabindex="-1"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>]</span>
<span id="cb84-8"><a href="arbres.html#cb84-8" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>,]    <span class="dv">0</span>    <span class="dv">1</span></span>
<span id="cb84-9"><a href="arbres.html#cb84-9" aria-hidden="true" tabindex="-1"></a>[<span class="dv">2</span>,]    <span class="dv">5</span>    <span class="dv">0</span></span>
<span id="cb84-10"><a href="arbres.html#cb84-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-11"><a href="arbres.html#cb84-11" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>split</span>
<span id="cb84-12"><a href="arbres.html#cb84-12" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb84-13"><a href="arbres.html#cb84-13" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(tree2)</span>
<span id="cb84-14"><a href="arbres.html#cb84-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-15"><a href="arbres.html#cb84-15" aria-hidden="true" tabindex="-1"></a>Classification tree<span class="sc">:</span></span>
<span id="cb84-16"><a href="arbres.html#cb84-16" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart</span>(<span class="at">formula =</span> High <span class="sc">~</span> ., <span class="at">data =</span> data1, <span class="at">parms =</span> <span class="fu">list</span>(<span class="at">loss =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>, </span>
<span id="cb84-17"><a href="arbres.html#cb84-17" aria-hidden="true" tabindex="-1"></a>    <span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">0</span>), <span class="at">ncol =</span> <span class="dv">2</span>)), <span class="at">cp =</span> <span class="fl">0.01</span>, <span class="at">minsplit =</span> <span class="dv">2</span>)</span>
<span id="cb84-18"><a href="arbres.html#cb84-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-19"><a href="arbres.html#cb84-19" aria-hidden="true" tabindex="-1"></a>Variables actually used <span class="cf">in</span> tree construction<span class="sc">:</span></span>
<span id="cb84-20"><a href="arbres.html#cb84-20" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] Advertising Age         CompPrice   Education  </span>
<span id="cb84-21"><a href="arbres.html#cb84-21" aria-hidden="true" tabindex="-1"></a>[<span class="dv">5</span>] Income      Population  Price       ShelveLoc  </span>
<span id="cb84-22"><a href="arbres.html#cb84-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-23"><a href="arbres.html#cb84-23" aria-hidden="true" tabindex="-1"></a>Root node error<span class="sc">:</span> <span class="dv">236</span><span class="sc">/</span><span class="dv">400</span> <span class="ot">=</span> <span class="fl">0.59</span></span>
<span id="cb84-24"><a href="arbres.html#cb84-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-25"><a href="arbres.html#cb84-25" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span> <span class="dv">400</span> </span>
<span id="cb84-26"><a href="arbres.html#cb84-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-27"><a href="arbres.html#cb84-27" aria-hidden="true" tabindex="-1"></a>         CP nsplit rel error xerror    xstd</span>
<span id="cb84-28"><a href="arbres.html#cb84-28" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>  <span class="fl">0.101695</span>      <span class="dv">0</span>   <span class="fl">1.00000</span> <span class="fl">5.0000</span> <span class="fl">0.20840</span></span>
<span id="cb84-29"><a href="arbres.html#cb84-29" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>  <span class="fl">0.050847</span>      <span class="dv">2</span>   <span class="fl">0.79661</span> <span class="fl">3.8136</span> <span class="fl">0.20909</span></span>
<span id="cb84-30"><a href="arbres.html#cb84-30" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>  <span class="fl">0.036017</span>      <span class="dv">3</span>   <span class="fl">0.74576</span> <span class="fl">3.2034</span> <span class="fl">0.20176</span></span>
<span id="cb84-31"><a href="arbres.html#cb84-31" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>  <span class="fl">0.035311</span>      <span class="dv">5</span>   <span class="fl">0.67373</span> <span class="fl">3.1271</span> <span class="fl">0.20038</span></span>
<span id="cb84-32"><a href="arbres.html#cb84-32" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>  <span class="fl">0.025424</span>      <span class="dv">9</span>   <span class="fl">0.50847</span> <span class="fl">2.6144</span> <span class="fl">0.19069</span></span>
<span id="cb84-33"><a href="arbres.html#cb84-33" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>  <span class="fl">0.016949</span>     <span class="dv">11</span>   <span class="fl">0.45763</span> <span class="fl">2.3475</span> <span class="fl">0.18307</span></span>
<span id="cb84-34"><a href="arbres.html#cb84-34" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>  <span class="fl">0.015537</span>     <span class="dv">16</span>   <span class="fl">0.37288</span> <span class="fl">2.1992</span> <span class="fl">0.17905</span></span>
<span id="cb84-35"><a href="arbres.html#cb84-35" aria-hidden="true" tabindex="-1"></a><span class="dv">8</span>  <span class="fl">0.014831</span>     <span class="dv">21</span>   <span class="fl">0.28814</span> <span class="fl">2.1992</span> <span class="fl">0.17905</span></span>
<span id="cb84-36"><a href="arbres.html#cb84-36" aria-hidden="true" tabindex="-1"></a><span class="dv">9</span>  <span class="fl">0.010593</span>     <span class="dv">23</span>   <span class="fl">0.25847</span> <span class="fl">2.0466</span> <span class="fl">0.17367</span></span>
<span id="cb84-37"><a href="arbres.html#cb84-37" aria-hidden="true" tabindex="-1"></a><span class="dv">10</span> <span class="fl">0.010000</span>     <span class="dv">25</span>   <span class="fl">0.23729</span> <span class="fl">2.0297</span> <span class="fl">0.17292</span></span></code></pre></div></li>
<li><p>Comparer les valeurs ajustées par les deux arbres considérés.</p></li>
</ol>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="lda.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="SVM.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TUTO_ML.pdf"],
"toc": {
"collapse": "subsection",
"sharing": {
"facebook": true,
"github": true,
"twitter": true
}
},
"highlight": "tango"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
