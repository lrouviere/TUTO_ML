<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 7 Données déséquilibrées | Machine learning</title>
  <meta name="description" content="Chapitre 7 Données déséquilibrées | Machine learning" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 7 Données déséquilibrées | Machine learning" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 7 Données déséquilibrées | Machine learning" />
  
  
  

<meta name="author" content="Laurent Rouvière" />


<meta name="date" content="2021-03-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="deep.html"/>
<link rel="next" href="comp-algo.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning<br> <br> L. Rouvière</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Présentation</a></li>
<li class="part"><span><b>I Algorithmes de référence</b></span></li>
<li class="chapter" data-level="1" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>1</b> Estimation du risque avec caret</a>
<ul>
<li class="chapter" data-level="1.1" data-path="caret.html"><a href="caret.html#notion-de-risque-en-apprentissage-supervisé"><i class="fa fa-check"></i><b>1.1</b> Notion de risque en apprentissage supervisé</a></li>
<li class="chapter" data-level="1.2" data-path="caret.html"><a href="caret.html#la-validation-croisée"><i class="fa fa-check"></i><b>1.2</b> La validation croisée</a></li>
<li class="chapter" data-level="1.3" data-path="caret.html"><a href="caret.html#le-package-caret"><i class="fa fa-check"></i><b>1.3</b> Le package caret</a></li>
<li class="chapter" data-level="1.4" data-path="caret.html"><a href="caret.html#la-courbe-roc"><i class="fa fa-check"></i><b>1.4</b> La courbe ROC</a></li>
<li class="chapter" data-level="1.5" data-path="caret.html"><a href="caret.html#compléments"><i class="fa fa-check"></i><b>1.5</b> Compléments</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="caret.html"><a href="caret.html#calcul-parallèle"><i class="fa fa-check"></i><b>1.5.1</b> Calcul parallèle</a></li>
<li class="chapter" data-level="1.5.2" data-path="caret.html"><a href="caret.html#répéter-les-méthodes-de-rééchantillonnage"><i class="fa fa-check"></i><b>1.5.2</b> Répéter les méthodes de rééchantillonnage</a></li>
<li class="chapter" data-level="1.5.3" data-path="caret.html"><a href="caret.html#modifier-le-risque"><i class="fa fa-check"></i><b>1.5.3</b> Modifier le risque</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lda.html"><a href="lda.html"><i class="fa fa-check"></i><b>2</b> Analyse discriminante linéaire</a>
<ul>
<li class="chapter" data-level="2.1" data-path="lda.html"><a href="lda.html#prise-en-main-lda-et-qda-sur-les-iris-de-fisher"><i class="fa fa-check"></i><b>2.1</b> Prise en main : LDA et QDA sur les iris de Fisher</a></li>
<li class="chapter" data-level="2.2" data-path="lda.html"><a href="lda.html#un-cas-avec-beaucoup-de-classes"><i class="fa fa-check"></i><b>2.2</b> Un cas avec beaucoup de classes</a></li>
<li class="chapter" data-level="2.3" data-path="lda.html"><a href="lda.html#grande-dimension-reconnaissance-de-phonèmes"><i class="fa fa-check"></i><b>2.3</b> Grande dimension : reconnaissance de phonèmes</a></li>
<li class="chapter" data-level="2.4" data-path="lda.html"><a href="lda.html#exercices"><i class="fa fa-check"></i><b>2.4</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arbres.html"><a href="arbres.html"><i class="fa fa-check"></i><b>3</b> Arbres</a>
<ul>
<li class="chapter" data-level="3.1" data-path="arbres.html"><a href="arbres.html#coupures-cart-en-fonction-de-la-nature-des-variables"><i class="fa fa-check"></i><b>3.1</b> Coupures CART en fonction de la nature des variables</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="arbres.html"><a href="arbres.html#arbres-de-régression"><i class="fa fa-check"></i><b>3.1.1</b> Arbres de régression</a></li>
<li class="chapter" data-level="3.1.2" data-path="arbres.html"><a href="arbres.html#arbres-de-classification"><i class="fa fa-check"></i><b>3.1.2</b> Arbres de classification</a></li>
<li class="chapter" data-level="3.1.3" data-path="arbres.html"><a href="arbres.html#entrée-qualitative"><i class="fa fa-check"></i><b>3.1.3</b> Entrée qualitative</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="arbres.html"><a href="arbres.html#élagage"><i class="fa fa-check"></i><b>3.2</b> Élagage</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="arbres.html"><a href="arbres.html#élagage-pour-un-problème-de-régression"><i class="fa fa-check"></i><b>3.2.1</b> Élagage pour un problème de régression</a></li>
<li class="chapter" data-level="3.2.2" data-path="arbres.html"><a href="arbres.html#élagage-en-classification-binaire-et-matrice-de-coût"><i class="fa fa-check"></i><b>3.2.2</b> Élagage en classification binaire et matrice de coût</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Algorithmes avancés</b></span></li>
<li class="chapter" data-level="4" data-path="SVM.html"><a href="SVM.html"><i class="fa fa-check"></i><b>4</b> Support Vector Machine (SVM)</a>
<ul>
<li class="chapter" data-level="4.1" data-path="SVM.html"><a href="SVM.html#cas-séparable"><i class="fa fa-check"></i><b>4.1</b> Cas séparable</a></li>
<li class="chapter" data-level="4.2" data-path="SVM.html"><a href="SVM.html#cas-non-séparable"><i class="fa fa-check"></i><b>4.2</b> Cas non séparable</a></li>
<li class="chapter" data-level="4.3" data-path="SVM.html"><a href="SVM.html#lastuce-du-noyau"><i class="fa fa-check"></i><b>4.3</b> L’astuce du noyau</a></li>
<li class="chapter" data-level="4.4" data-path="SVM.html"><a href="SVM.html#support-vector-régression"><i class="fa fa-check"></i><b>4.4</b> Support vector régression</a></li>
<li class="chapter" data-level="4.5" data-path="SVM.html"><a href="SVM.html#svm-sur-les-données-spam"><i class="fa fa-check"></i><b>4.5</b> SVM sur les données spam</a></li>
<li class="chapter" data-level="4.6" data-path="SVM.html"><a href="SVM.html#exercices-1"><i class="fa fa-check"></i><b>4.6</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agregation.html"><a href="agregation.html"><i class="fa fa-check"></i><b>5</b> Agrégation : forêts aléatoires et gradient boosting</a>
<ul>
<li class="chapter" data-level="5.1" data-path="agregation.html"><a href="agregation.html#forets"><i class="fa fa-check"></i><b>5.1</b> Forêts aléatoires</a></li>
<li class="chapter" data-level="5.2" data-path="agregation.html"><a href="agregation.html#boosting"><i class="fa fa-check"></i><b>5.2</b> Gradient boosting</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="agregation.html"><a href="agregation.html#un-exemple-simple-en-régression"><i class="fa fa-check"></i><b>5.2.1</b> Un exemple simple en régression</a></li>
<li class="chapter" data-level="5.2.2" data-path="agregation.html"><a href="agregation.html#adaboost-et-logitboost-pour-la-classification-binaire."><i class="fa fa-check"></i><b>5.2.2</b> Adaboost et logitboost pour la classification binaire.</a></li>
<li class="chapter" data-level="5.2.3" data-path="agregation.html"><a href="agregation.html#exo:grad-boost"><i class="fa fa-check"></i><b>5.2.3</b> Exercices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="deep.html"><a href="deep.html"><i class="fa fa-check"></i><b>6</b> Réseaux de neurones avec Keras</a></li>
<li class="chapter" data-level="7" data-path="dondes.html"><a href="dondes.html"><i class="fa fa-check"></i><b>7</b> Données déséquilibrées</a>
<ul>
<li class="chapter" data-level="7.1" data-path="dondes.html"><a href="dondes.html#critères-de-performance-pour-données-déséquilibrées"><i class="fa fa-check"></i><b>7.1</b> Critères de performance pour données déséquilibrées</a></li>
<li class="chapter" data-level="7.2" data-path="dondes.html"><a href="dondes.html#ré-équilibrage"><i class="fa fa-check"></i><b>7.2</b> Ré-équilibrage</a></li>
<li class="chapter" data-level="7.3" data-path="dondes.html"><a href="dondes.html#exercices-supplémentaires"><i class="fa fa-check"></i><b>7.3</b> Exercices supplémentaires</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="comp-algo.html"><a href="comp-algo.html"><i class="fa fa-check"></i><b>8</b> Comparaison d’algorithmes</a></li>
<li class="chapter" data-level="" data-path="références.html"><a href="références.html"><i class="fa fa-check"></i>Références</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dondes" class="section level1" number="7">
<h1><span class="header-section-number">Chapitre 7</span> Données déséquilibrées</h1>
<p>On parle de <strong>données déséquilibrées</strong> lorsque les deux modalités de la variable cible <span class="math inline">\(Y\)</span> ne sont pas représentées de façon égale dans l’échantillon, ou plus précisément lorsqu’une des deux modalités est fortement majoritaire. Ce contexte est fréquemment rencontré en pratique, on peut citer les cas de détection de fraudes (peu de fraudeurs), de la présence d’une maladie rare (peu de patients atteints), du risque de crédit (peu de mauvais payeurs)… Les algorithmes standards peuvent être mis en difficultés et de nouvelles stratégies doivent être élaborées. Les stratégies classiques permettant de répondre à ce problème consistent à</p>
<ul>
<li>utiliser des critères de performance adaptés au déséquilibre ;</li>
<li>ré-échantillonner les données pour se rapprocher d’une situation d’équilibre.</li>
</ul>
<p>Nous présentons ces stratégies à travers quelques exercices.</p>
<div id="critères-de-performance-pour-données-déséquilibrées" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Critères de performance pour données déséquilibrées</h2>
<p>La notion de <strong>risque</strong> en machine learning est capitale puisque c’est à partir de l’estimation de ces risques que l’on <strong>calibre des algorithmes</strong> et que l’on <strong>choisit un algorithme de prévision</strong>. En présence de données déséquilibré, il convient de choisir un risque adapté. En effet, il est le plus souvent important de parvenir à bien identifier des individus de la classe minoritaire. Des critères tels que l’accuracy ou l’erreur de classification ne sont pas pertinents pour ce cadre. On va privilégier des critères comme</p>
<ul>
<li>le <strong>balanced accuracy</strong>
<span class="math display">\[\text{Bal Acc}=\frac{1}{2}\mathbf P(g(X)=1|Y=1)+\frac{1}{2}\mathbf P(g(X)=-1|Y=-1)=\frac{\text{TPR+TNR}}{2}.\]</span></li>
<li>le <strong><span class="math inline">\(F_1\)</span>-score</strong>
<span class="math display">\[F_1=2\,\frac{\text{Precision }\times\text{Recall}}{\text{Precision }+\text{Recall}},\]</span>
avec
<span class="math display">\[\text{Precision}=\mathbf P(Y=1|g(X)=1)\quad\text{et}\quad\text{Recall}=\mathbf P(g(X)=1|Y=1).\]</span></li>
<li>le <strong>kappa de Cohen</strong>
<span class="math display">\[\kappa=\frac{\mathbf P(a)-\mathbf P(e)}{1-\mathbf P(e)}\]</span>
où <span class="math inline">\(\mathbf P(a)\)</span> représente l’accuracy et <span class="math inline">\(\mathbf P(e)\)</span> l’accuracy sous une hypothèse d’indépendance.</li>
<li>la courbe ROC et l’AUC…</li>
</ul>
<p>Comme d’habitude, ces critères sont inconnus et doivent être estimés par des méthodes de ré-échantillonnage de type validation croisée.</p>

<div class="exercise">
<span id="exr:exo-dondes-calc-criteres" class="exercise"><strong>Exercice 7.1  (Calculer des critères)  </strong></span>
</div>
<ol style="list-style-type: decimal">
<li><p>Générer un vecteur d’observations <strong>Y</strong> de taille 500 selon une loi de Bernoulli de paramètre 0.05.</p></li>
<li><p>Générer un vecteur de prévisions <strong>P1</strong> de taille 500 selon une loi de Bernoulli de paramètre 0.01.</p></li>
<li><p>Générer un vecteur de prévision <strong>P2</strong> de taille 500 tel que
<span class="math display">\[\mathcal L(P2|Y=0)=\mathcal B(0.10)\quad\text{et}\quad \mathcal L(P2|Y=1)=\mathcal B(0.85).\]</span></p></li>
<li><p>Dresser les tables de contingence de <strong>P1</strong> et <strong>P2</strong> à l’aide de <strong>table</strong>. Commenter.</p></li>
<li><p>Pour <strong>P2</strong>, calculer, avec les fonctions usuelles de <code>R</code>, l’<strong>accuracy</strong>, le <strong>recall</strong> et la <strong>précision</strong>.</p></li>
<li><p>En déduire le F1-score.</p></li>
<li><p>Même question pour le <span class="math inline">\(\kappa\)</span> de Cohen.</p></li>
<li><p>Retrouver ces indicateurs à l’aide de la fonction <strong>confusionMatrix</strong> de <strong>caret</strong> puis comparer les prévisions <strong>P1</strong> et <strong>P2</strong>.</p></li>
</ol>
</div>
<div id="ré-équilibrage" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Ré-équilibrage</h2>
<p>En complément du choix d’un <strong>critère pertinent</strong>, il peut être intéressant de tenter de <strong>ré-équilibrer</strong> l’échantillon pour aider les algorithmes à mieux <strong>détecter les individus de la classe minoritaire</strong>. Les méthodes classiques consistent à créer de nouvelles observations de la classe minoritaire (<strong>oversampling</strong>) et/ou supprimer des individus de la classe minoritaire (<strong>undersampling</strong>).</p>

<div class="exercise">
<span id="exr:exo-dondes-etude-reeq" class="exercise"><strong>Exercice 7.2  (Quelques algorithmes de ré-équilibrage)  </strong></span>
</div>
<p>On considère le jeu de données <code>df</code> ci-dessous où on cherche à prédire <code>Y</code> par <code>X1</code> et <code>X2</code>.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="dondes.html#cb111-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb111-2"><a href="dondes.html#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb111-3"><a href="dondes.html#cb111-3" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb111-4"><a href="dondes.html#cb111-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5678</span>)</span>
<span id="cb111-5"><a href="dondes.html#cb111-5" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb111-6"><a href="dondes.html#cb111-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">9012</span>)</span>
<span id="cb111-7"><a href="dondes.html#cb111-7" aria-hidden="true" tabindex="-1"></a>R1 <span class="ot">&lt;-</span> X1<span class="sc">&lt;=</span><span class="fl">0.25</span></span>
<span id="cb111-8"><a href="dondes.html#cb111-8" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> (X1<span class="sc">&gt;</span><span class="fl">0.25</span> <span class="sc">&amp;</span> X2<span class="sc">&gt;=</span><span class="fl">0.75</span>)</span>
<span id="cb111-9"><a href="dondes.html#cb111-9" aria-hidden="true" tabindex="-1"></a>R3 <span class="ot">&lt;-</span> (X1<span class="sc">&gt;</span><span class="fl">0.25</span> <span class="sc">&amp;</span> X2<span class="sc">&lt;</span><span class="fl">0.75</span>)</span>
<span id="cb111-10"><a href="dondes.html#cb111-10" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,n)</span>
<span id="cb111-11"><a href="dondes.html#cb111-11" aria-hidden="true" tabindex="-1"></a>Y[R1] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(R1),<span class="dv">1</span>,<span class="fl">0.75</span>)</span>
<span id="cb111-12"><a href="dondes.html#cb111-12" aria-hidden="true" tabindex="-1"></a>Y[R2] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(R2),<span class="dv">1</span>,<span class="fl">0.75</span>)</span>
<span id="cb111-13"><a href="dondes.html#cb111-13" aria-hidden="true" tabindex="-1"></a>Y[R3] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(R3),<span class="dv">1</span>,<span class="fl">0.25</span>)</span>
<span id="cb111-14"><a href="dondes.html#cb111-14" aria-hidden="true" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(X1,X2,Y)</span>
<span id="cb111-15"><a href="dondes.html#cb111-15" aria-hidden="true" tabindex="-1"></a>df1<span class="sc">$</span>Y <span class="ot">&lt;-</span> <span class="fu">factor</span>(df1<span class="sc">$</span>Y)</span>
<span id="cb111-16"><a href="dondes.html#cb111-16" aria-hidden="true" tabindex="-1"></a>indDY1 <span class="ot">&lt;-</span> <span class="fu">which</span>(df1<span class="sc">$</span>Y<span class="sc">==</span><span class="dv">1</span>)</span>
<span id="cb111-17"><a href="dondes.html#cb111-17" aria-hidden="true" tabindex="-1"></a>df1<span class="fl">.1</span> <span class="ot">&lt;-</span> df1[<span class="sc">-</span>indDY1[<span class="dv">1</span><span class="sc">:</span><span class="dv">650</span>],]</span>
<span id="cb111-18"><a href="dondes.html#cb111-18" aria-hidden="true" tabindex="-1"></a>df1<span class="fl">.2</span> <span class="ot">&lt;-</span> df1<span class="fl">.1</span>[<span class="fu">sample</span>(<span class="fu">nrow</span>(df1<span class="fl">.1</span>),<span class="dv">1000</span>),]</span>
<span id="cb111-19"><a href="dondes.html#cb111-19" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df1<span class="fl">.2</span>[<span class="fu">sample</span>(<span class="fu">nrow</span>(df1<span class="fl">.2</span>),<span class="dv">100</span>),]</span>
<span id="cb111-20"><a href="dondes.html#cb111-20" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(df) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb111-21"><a href="dondes.html#cb111-21" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df)<span class="sc">+</span><span class="fu">aes</span>(<span class="at">x=</span>X1,<span class="at">y=</span>X2,<span class="at">color=</span>Y)<span class="sc">+</span><span class="fu">geom_point</span>()</span>
<span id="cb111-22"><a href="dondes.html#cb111-22" aria-hidden="true" tabindex="-1"></a>p1</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-367-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>On a ici 4 fois plus d’observations dans le groupe 0.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="dondes.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(df<span class="sc">$</span>Y)</span>
<span id="cb112-2"><a href="dondes.html#cb112-2" aria-hidden="true" tabindex="-1"></a> <span class="dv">0</span>  <span class="dv">1</span> </span>
<span id="cb112-3"><a href="dondes.html#cb112-3" aria-hidden="true" tabindex="-1"></a><span class="dv">80</span> <span class="dv">20</span> </span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>On commence par faire du <strong>oversampling</strong> avec la fonction <code>RandOverClassif</code>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Effectuer le ré-échantillonnage et expliquer.</p></li>
<li><p>Corriger les paramètres de la fonction de manière à avoir 80 observations dans le groupe 0 et 60 dans le groupe 1.</p></li>
</ol></li>
<li><p>On s’intéresse maintenant à l’algorithme <strong>SMOTE</strong></p>
<ol style="list-style-type: lower-alpha">
<li><p>Exécuter la fonction <strong>SmoteClassif</strong> avec <code>k=3</code> et les les paramètres par défaut</p></li>
<li><p>Visualiser les <strong>observations smote</strong>.</p></li>
<li><p>Corriger les paramètres de la fonction de manière à avoir 80 observations dans le groupe 0 et 60 dans le groupe 1.</p></li>
</ol></li>
<li><p>On souhaite maintenant ré-équilibrer par <strong>random undersampling</strong>. Utiliser la fonction <strong>RandUnderClassif</strong> pour effectuer un tel ré-équilibrage. Ici encore on pourra faire varier les paramètres.</p></li>
<li><p>On passe maintenant à l’algorithme <strong>Tomek</strong>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Sans utiliser la fonction <strong>TomekClassif</strong> identifier les paires d’observations qui ont un <strong>lien de Tomek</strong>. On pourra utiliser la fonction <strong>nng</strong> du package <code>cccd</code>.</p></li>
<li><p>Retrouver ces paires à l’aide de la fonction Tomek LinK.</p></li>
<li><p>Visualiser les observations supprimées. On prendra soin d’expliquer l’option <code>rem</code> de <strong>TomekClassif</strong>.</p></li>
</ol></li>
</ol>

<div class="exercise">
<span id="exr:exo-dondes-comp-reeq" class="exercise"><strong>Exercice 7.3  (Comparaison de méthodes de ré-équilibrage)  </strong></span>
</div>
<p>On considère 3 jeux de données <code>df1</code>, <code>df2</code> et <code>df3</code>.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="dondes.html#cb113-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb113-2"><a href="dondes.html#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb113-3"><a href="dondes.html#cb113-3" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb113-4"><a href="dondes.html#cb113-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5678</span>)</span>
<span id="cb113-5"><a href="dondes.html#cb113-5" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb113-6"><a href="dondes.html#cb113-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">9012</span>)</span>
<span id="cb113-7"><a href="dondes.html#cb113-7" aria-hidden="true" tabindex="-1"></a>R1 <span class="ot">&lt;-</span> X1<span class="sc">&lt;=</span><span class="fl">0.25</span></span>
<span id="cb113-8"><a href="dondes.html#cb113-8" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> (X1<span class="sc">&gt;</span><span class="fl">0.25</span> <span class="sc">&amp;</span> X2<span class="sc">&gt;=</span><span class="fl">0.75</span>)</span>
<span id="cb113-9"><a href="dondes.html#cb113-9" aria-hidden="true" tabindex="-1"></a>R3 <span class="ot">&lt;-</span> (X1<span class="sc">&gt;</span><span class="fl">0.25</span> <span class="sc">&amp;</span> X2<span class="sc">&lt;</span><span class="fl">0.75</span>)</span>
<span id="cb113-10"><a href="dondes.html#cb113-10" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,n)</span>
<span id="cb113-11"><a href="dondes.html#cb113-11" aria-hidden="true" tabindex="-1"></a>Y[R1] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(R1),<span class="dv">1</span>,<span class="fl">0.75</span>)</span>
<span id="cb113-12"><a href="dondes.html#cb113-12" aria-hidden="true" tabindex="-1"></a>Y[R2] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(R2),<span class="dv">1</span>,<span class="fl">0.75</span>)</span>
<span id="cb113-13"><a href="dondes.html#cb113-13" aria-hidden="true" tabindex="-1"></a>Y[R3] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fu">sum</span>(R3),<span class="dv">1</span>,<span class="fl">0.25</span>)</span>
<span id="cb113-14"><a href="dondes.html#cb113-14" aria-hidden="true" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(X1,X2,Y)</span>
<span id="cb113-15"><a href="dondes.html#cb113-15" aria-hidden="true" tabindex="-1"></a>df1<span class="sc">$</span>Y <span class="ot">&lt;-</span> <span class="fu">factor</span>(df1<span class="sc">$</span>Y)</span>
<span id="cb113-16"><a href="dondes.html#cb113-16" aria-hidden="true" tabindex="-1"></a>indDY1 <span class="ot">&lt;-</span> <span class="fu">which</span>(df1<span class="sc">$</span>Y<span class="sc">==</span><span class="dv">1</span>)</span>
<span id="cb113-17"><a href="dondes.html#cb113-17" aria-hidden="true" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> df1[<span class="sc">-</span>indDY1[<span class="dv">1</span><span class="sc">:</span><span class="dv">400</span>],]</span>
<span id="cb113-18"><a href="dondes.html#cb113-18" aria-hidden="true" tabindex="-1"></a>df3 <span class="ot">&lt;-</span> df1[<span class="sc">-</span>indDY1[<span class="dv">1</span><span class="sc">:</span><span class="dv">700</span>],]</span>
<span id="cb113-19"><a href="dondes.html#cb113-19" aria-hidden="true" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> df1[<span class="fu">sample</span>(<span class="fu">nrow</span>(df1),<span class="dv">1000</span>),]</span>
<span id="cb113-20"><a href="dondes.html#cb113-20" aria-hidden="true" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> df2[<span class="fu">sample</span>(<span class="fu">nrow</span>(df2),<span class="dv">1000</span>),]</span>
<span id="cb113-21"><a href="dondes.html#cb113-21" aria-hidden="true" tabindex="-1"></a>df3 <span class="ot">&lt;-</span> df3[<span class="fu">sample</span>(<span class="fu">nrow</span>(df3),<span class="dv">1000</span>),]</span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>Comparer la distribution de <strong>Y</strong> pour ces trois jeux de données et visualiser les observations.</p></li>
<li><p>On sépare ces 3 échantillons en un échantillon d’apprentissage et un échantillon test.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="dondes.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb114-2"><a href="dondes.html#cb114-2" aria-hidden="true" tabindex="-1"></a>a1 <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df1),<span class="at">p=</span><span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>)</span>
<span id="cb114-3"><a href="dondes.html#cb114-3" aria-hidden="true" tabindex="-1"></a>a2 <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df2),<span class="at">p=</span><span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>)</span>
<span id="cb114-4"><a href="dondes.html#cb114-4" aria-hidden="true" tabindex="-1"></a>a3 <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df3),<span class="at">p=</span><span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>)</span>
<span id="cb114-5"><a href="dondes.html#cb114-5" aria-hidden="true" tabindex="-1"></a>train1 <span class="ot">&lt;-</span> df1[a1<span class="sc">$</span>Resample1,]</span>
<span id="cb114-6"><a href="dondes.html#cb114-6" aria-hidden="true" tabindex="-1"></a>train2 <span class="ot">&lt;-</span> df2[a2<span class="sc">$</span>Resample1,]</span>
<span id="cb114-7"><a href="dondes.html#cb114-7" aria-hidden="true" tabindex="-1"></a>train3 <span class="ot">&lt;-</span> df3[a3<span class="sc">$</span>Resample1,]</span>
<span id="cb114-8"><a href="dondes.html#cb114-8" aria-hidden="true" tabindex="-1"></a>test1 <span class="ot">&lt;-</span> df1[<span class="sc">-</span>a1<span class="sc">$</span>Resample1,]</span>
<span id="cb114-9"><a href="dondes.html#cb114-9" aria-hidden="true" tabindex="-1"></a>test2 <span class="ot">&lt;-</span> df2[<span class="sc">-</span>a2<span class="sc">$</span>Resample1,]</span>
<span id="cb114-10"><a href="dondes.html#cb114-10" aria-hidden="true" tabindex="-1"></a>test3 <span class="ot">&lt;-</span> df3[<span class="sc">-</span>a3<span class="sc">$</span>Resample1,]</span></code></pre></div>
<p>Ajuster une forêt aléatoire sur les 3 échantillon d’apprentissage, calculer les labels prédits sur les échantillons tests et estimer les différents indicateurs vus en cours à l’aide de <strong>confusionMatrix</strong>.</p></li>
<li><p>On considère uniquement l’échantillon <strong>df3</strong>. Refaire l’analyse précédente en utilisant des techniques de ré-échantillonnage.</p></li>
</ol>
</div>
<div id="exercices-supplémentaires" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Exercices supplémentaires</h2>

<div class="exercise">
<span id="exr:exo-dondes-echret" class="exercise"><strong>Exercice 7.4  (Echantillonnage rétrospectif)  </strong></span>
</div>
<p>Dans le cadre de l’échantillonnage rétrospectif pour le modèle logistique vu en cours, démontrer la propriété qui lie le modèle logistique initial au modèle ré-équilibré.</p>

<div class="exercise">
<span id="exr:exo-dondes-cas-temoins" class="exercise"><strong>Exercice 7.5  (Echantillonnage rétrospectif)  </strong></span>
</div>
<p>Une étude cas/témoins est réalisée pour mesurer l’effet du tabac sur une pathologie. Pour ce faire, on choisit <span class="math inline">\(n_1=250\)</span> patients atteints de la pathologie (cas) et <span class="math inline">\(n_0=250\)</span> patients sains (témoins). Les résultats de l’étude sont présentés ci-dessous</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">Fumeur</th>
<th align="center">Non fumeur</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Non malade</td>
<td align="center">48</td>
<td align="center">202</td>
</tr>
<tr class="even">
<td align="center">Malade</td>
<td align="center">208</td>
<td align="center">42</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li><p>A partir des données obtenues, estimer à l’aide d’un modèle logistique la probabilité d’être atteint pour un fumeur, puis pour un non fumeur.</p></li>
<li><p>Comment interpréter ces deux probabilités ? Est-ce qu’elles estiment la probabilité d’être atteint pour un individu quelconque dans la population ?</p></li>
<li><p>Des études précédentes ont montré que cinq individus sur mille sont atteints par la pathologie dans la population entière. En utilisant la propriété de l’exercice précédent, en déduire les probabilités d’être atteint pour un fumeur et un non fumeur dans la population.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="deep.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comp-algo.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TUTO_ML.pdf"],
"toc": {
"collapse": "subsection",
"sharing": {
"facebook": true,
"github": true,
"twitter": true
}
},
"highlight": "tango"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
