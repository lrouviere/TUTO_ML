<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 7 Données déséquilibrées | Machine learning</title>
  <meta name="description" content="Chapitre 7 Données déséquilibrées | Machine learning" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 7 Données déséquilibrées | Machine learning" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 7 Données déséquilibrées | Machine learning" />
  
  
  

<meta name="author" content="Laurent Rouvière" />


<meta name="date" content="2020-12-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="deep.html"/>
<link rel="next" href="comp-algo.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.9/visNetwork.js"></script>
<script src="libs/FileSaver-1.1.20151003/FileSaver.min.js"></script>
<script src="libs/Blob-1.0/Blob.js"></script>
<script src="libs/canvas-toBlob-1.0/canvas-toBlob.js"></script>
<script src="libs/html2canvas-0.5.0/html2canvas.js"></script>
<script src="libs/jspdf-1.3.2/jspdf.debug.js"></script>
<link href="libs/jquery-sparkline-2.1.2/jquery.sparkline.css" rel="stylesheet" />
<script src="libs/jquery-sparkline-2.1.2/jquery.sparkline.js"></script>
<script src="libs/sparkline-binding-2.0/sparkline.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning<br> <br> L. Rouvière</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Présentation</a></li>
<li class="part"><span><b>I Algorithmes de référence</b></span></li>
<li class="chapter" data-level="1" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>1</b> Estimation du risque avec caret</a><ul>
<li class="chapter" data-level="1.1" data-path="caret.html"><a href="caret.html#notion-de-risque-en-apprentissage-supervisé"><i class="fa fa-check"></i><b>1.1</b> Notion de risque en apprentissage supervisé</a></li>
<li class="chapter" data-level="1.2" data-path="caret.html"><a href="caret.html#la-validation-croisée"><i class="fa fa-check"></i><b>1.2</b> La validation croisée</a></li>
<li class="chapter" data-level="1.3" data-path="caret.html"><a href="caret.html#le-package-caret"><i class="fa fa-check"></i><b>1.3</b> Le package caret</a></li>
<li class="chapter" data-level="1.4" data-path="caret.html"><a href="caret.html#compléments"><i class="fa fa-check"></i><b>1.4</b> Compléments</a><ul>
<li class="chapter" data-level="1.4.1" data-path="caret.html"><a href="caret.html#calcul-parallèle"><i class="fa fa-check"></i><b>1.4.1</b> Calcul parallèle</a></li>
<li class="chapter" data-level="1.4.2" data-path="caret.html"><a href="caret.html#répéter-les-méthodes-de-rééchantillonnage"><i class="fa fa-check"></i><b>1.4.2</b> Répéter les méthodes de rééchantillonnage</a></li>
<li class="chapter" data-level="1.4.3" data-path="caret.html"><a href="caret.html#modifier-le-risque"><i class="fa fa-check"></i><b>1.4.3</b> Modifier le risque</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lda.html"><a href="lda.html"><i class="fa fa-check"></i><b>2</b> Analyse discriminante linéaire</a><ul>
<li class="chapter" data-level="2.1" data-path="lda.html"><a href="lda.html#prise-en-main-lda-et-qda-sur-les-iris-de-fisher"><i class="fa fa-check"></i><b>2.1</b> Prise en main : LDA et QDA sur les iris de Fisher</a></li>
<li class="chapter" data-level="2.2" data-path="lda.html"><a href="lda.html#un-cas-avec-beaucoup-de-classes"><i class="fa fa-check"></i><b>2.2</b> Un cas avec beaucoup de classes</a></li>
<li class="chapter" data-level="2.3" data-path="lda.html"><a href="lda.html#grande-dimension-reconnaissance-de-phonèmes"><i class="fa fa-check"></i><b>2.3</b> Grande dimension : reconnaissance de phonèmes</a></li>
<li class="chapter" data-level="2.4" data-path="lda.html"><a href="lda.html#exercices"><i class="fa fa-check"></i><b>2.4</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arbres.html"><a href="arbres.html"><i class="fa fa-check"></i><b>3</b> Arbres</a><ul>
<li class="chapter" data-level="3.1" data-path="arbres.html"><a href="arbres.html#coupures-cart-en-fonction-de-la-nature-des-variables"><i class="fa fa-check"></i><b>3.1</b> Coupures CART en fonction de la nature des variables</a><ul>
<li class="chapter" data-level="3.1.1" data-path="arbres.html"><a href="arbres.html#arbres-de-régression"><i class="fa fa-check"></i><b>3.1.1</b> Arbres de régression</a></li>
<li class="chapter" data-level="3.1.2" data-path="arbres.html"><a href="arbres.html#arbres-de-classification"><i class="fa fa-check"></i><b>3.1.2</b> Arbres de classification</a></li>
<li class="chapter" data-level="3.1.3" data-path="arbres.html"><a href="arbres.html#entrée-qualitative"><i class="fa fa-check"></i><b>3.1.3</b> Entrée qualitative</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="arbres.html"><a href="arbres.html#élagage"><i class="fa fa-check"></i><b>3.2</b> Élagage</a><ul>
<li class="chapter" data-level="3.2.1" data-path="arbres.html"><a href="arbres.html#élagage-pour-un-problème-de-régression"><i class="fa fa-check"></i><b>3.2.1</b> Élagage pour un problème de régression</a></li>
<li class="chapter" data-level="3.2.2" data-path="arbres.html"><a href="arbres.html#élagage-en-classification-binaire-et-matrice-de-coût"><i class="fa fa-check"></i><b>3.2.2</b> Élagage en classification binaire et matrice de coût</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Algorithmes avancés</b></span></li>
<li class="chapter" data-level="4" data-path="SVM.html"><a href="SVM.html"><i class="fa fa-check"></i><b>4</b> Support Vector Machine (SVM)</a><ul>
<li class="chapter" data-level="4.1" data-path="SVM.html"><a href="SVM.html#cas-séparable"><i class="fa fa-check"></i><b>4.1</b> Cas séparable</a></li>
<li class="chapter" data-level="4.2" data-path="SVM.html"><a href="SVM.html#cas-non-séparable"><i class="fa fa-check"></i><b>4.2</b> Cas non séparable</a></li>
<li class="chapter" data-level="4.3" data-path="SVM.html"><a href="SVM.html#lastuce-du-noyau"><i class="fa fa-check"></i><b>4.3</b> L’astuce du noyau</a></li>
<li class="chapter" data-level="4.4" data-path="SVM.html"><a href="SVM.html#support-vector-régression"><i class="fa fa-check"></i><b>4.4</b> Support vector régression</a></li>
<li class="chapter" data-level="4.5" data-path="SVM.html"><a href="SVM.html#svm-sur-les-données-spam"><i class="fa fa-check"></i><b>4.5</b> SVM sur les données spam</a></li>
<li class="chapter" data-level="4.6" data-path="SVM.html"><a href="SVM.html#exercices-1"><i class="fa fa-check"></i><b>4.6</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agregation.html"><a href="agregation.html"><i class="fa fa-check"></i><b>5</b> Agrégation : forêts aléatoires et gradient boosting</a><ul>
<li class="chapter" data-level="5.1" data-path="agregation.html"><a href="agregation.html#forets"><i class="fa fa-check"></i><b>5.1</b> Forêts aléatoires</a></li>
<li class="chapter" data-level="5.2" data-path="agregation.html"><a href="agregation.html#boosting"><i class="fa fa-check"></i><b>5.2</b> Gradient boosting</a><ul>
<li class="chapter" data-level="5.2.1" data-path="agregation.html"><a href="agregation.html#un-exemple-simple-en-régression"><i class="fa fa-check"></i><b>5.2.1</b> Un exemple simple en régression</a></li>
<li class="chapter" data-level="5.2.2" data-path="agregation.html"><a href="agregation.html#adaboost-et-logitboost-pour-la-classification-binaire."><i class="fa fa-check"></i><b>5.2.2</b> Adaboost et logitboost pour la classification binaire.</a></li>
<li class="chapter" data-level="5.2.3" data-path="agregation.html"><a href="agregation.html#exo:grad-boost"><i class="fa fa-check"></i><b>5.2.3</b> Exercices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="deep.html"><a href="deep.html"><i class="fa fa-check"></i><b>6</b> Réseaux de neurones avec Keras</a></li>
<li class="chapter" data-level="7" data-path="dondes.html"><a href="dondes.html"><i class="fa fa-check"></i><b>7</b> Données déséquilibrées</a><ul>
<li class="chapter" data-level="7.1" data-path="dondes.html"><a href="dondes.html#critères-de-performance-pour-données-déséquilibrées"><i class="fa fa-check"></i><b>7.1</b> Critères de performance pour données déséquilibrées</a></li>
<li class="chapter" data-level="7.2" data-path="dondes.html"><a href="dondes.html#ré-équilibrage"><i class="fa fa-check"></i><b>7.2</b> Ré-équilibrage</a></li>
<li class="chapter" data-level="7.3" data-path="dondes.html"><a href="dondes.html#exercices-supplémentaires"><i class="fa fa-check"></i><b>7.3</b> Exercices supplémentaires</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="comp-algo.html"><a href="comp-algo.html"><i class="fa fa-check"></i><b>8</b> Comparaison d’algorithmes</a></li>
<li class="chapter" data-level="" data-path="références.html"><a href="références.html"><i class="fa fa-check"></i>Références</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dondes" class="section level1">
<h1><span class="header-section-number">Chapitre 7</span> Données déséquilibrées</h1>
<p>On parle de <strong>données déséquilibrées</strong> lorsque les deux modalités de la variable cible <span class="math inline">\(Y\)</span> ne sont pas représentées de façon égale dans l’échantillon, ou plus précisément lorsqu’une des deux modalités est fortement majoritaire. Ce contexte est fréquemment rencontré en pratique, on peut citer les cas de détection de fraudes (peu de fraudeurs), de la présence d’une maladie rare (peu de patients atteints), du risque de crédit (peu de mauvais payeurs)… Les algorithmes standards peuvent être mis en difficultés et de nouvelles stratégies doivent être élaborées. Les stratégies classiques permettant de répondre à ce problème consistent à</p>
<ul>
<li>utiliser des critères de performance adaptés au déséquilibre ;</li>
<li>ré-échantilloner les données pour se rapprocher d’une situation d’équilibre.</li>
</ul>
<p>Nous présentons ces stratégies à travers quelques exercices.</p>
<div id="critères-de-performance-pour-données-déséquilibrées" class="section level2">
<h2><span class="header-section-number">7.1</span> Critères de performance pour données déséquilibrées</h2>
<p>La notion de <strong>risque</strong> en machine learning est capitale puisque c’est à partir de l’estimation de ces risques que l’on <strong>calibre des algorithmes</strong> et que l’on <strong>choisit un algorithme de prévision</strong>. En présence de données déséquilibré, il convient de choisir un risque adapté. En effet, il est le plus souvent important de parvenir à bien identifier des individus de la classe minoritaire. Des critères tels que l’accuracy ou l’erreur de classification ne sont pas pertinents pour ce cadre. On va privilégier des critères comme</p>
<ul>
<li>le <strong>balanced accuracy</strong>
<span class="math display">\[\text{Bal Acc}=\frac{1}{2}\mathbf P(g(X)=1|Y=1)+\frac{1}{2}\mathbf P(g(X)=-1|Y=-1)=\frac{\text{TPR+TNR}}{2}.\]</span></li>
<li>le <strong><span class="math inline">\(F_1\)</span>-score</strong>
<span class="math display">\[F_1=2\,\frac{\text{Precision }\times\text{Recall}}{\text{Precision }+\text{Recall}},\]</span>
avec
<span class="math display">\[\text{Precision}=\mathbf P(Y=1|g(X)=1)\quad\text{et}\quad\text{Recall}=\mathbf P(g(X)=1|Y=1).\]</span></li>
<li>le <strong>kappa de Cohen</strong>
<span class="math display">\[\kappa=\frac{\mathbf P(a)-\mathbf P(e)}{1-\mathbf P(e)}\]</span>
où <span class="math inline">\(\mathbf P(a)\)</span> représente l’accuraci et <span class="math inline">\(\mathbf P(e)\)</span> l’accuracy sous une hypothèse d’indépendance.</li>
<li>la courbe ROC et l’AUC…</li>
</ul>
<p>Comme d’habitude, ces critères sont inconnus et doivent être estimés par des méthodes de ré-échantillonnage de type validation croisée.</p>

<div class="exercise">
<span id="exr:exo-dondes-calc-criteres" class="exercise"><strong>Exercice 7.1  (Calculer des critères)  </strong></span>
</div>

<ol style="list-style-type: decimal">
<li><p>Générer un vecteur d’observations <strong>Y</strong> de taille 500 selon une loi de Bernoulli de paramètre 0.05.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="dondes.html#cb217-1"></a><span class="kw">set.seed</span>(<span class="dv">1235</span>)</span>
<span id="cb217-2"><a href="dondes.html#cb217-2"></a>n &lt;-<span class="st"> </span><span class="dv">500</span></span>
<span id="cb217-3"><a href="dondes.html#cb217-3"></a>Y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n,<span class="dv">1</span>,<span class="fl">0.05</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</span></code></pre></div></li>
<li><p>Générer un vecteur de prévisions <strong>P1</strong> de taille 500 selon une loi de Bernoulli de paramètre 0.01.</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="dondes.html#cb218-1"></a><span class="kw">set.seed</span>(<span class="dv">987654321</span>)</span>
<span id="cb218-2"><a href="dondes.html#cb218-2"></a>P1 &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n,<span class="dv">1</span>,<span class="fl">0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">factor</span>(<span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;0&quot;</span>,<span class="st">&quot;1&quot;</span>))</span></code></pre></div></li>
<li><p>Générer un vecteur de prévision <strong>P2</strong> de taille 500 tel que
<span class="math display">\[\mathcal L(P2|Y=0)=\mathcal B(0.10)\quad\text{et}\quad \mathcal L(P2|Y=1)=\mathcal B(0.85).\]</span></p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="dondes.html#cb219-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb219-2"><a href="dondes.html#cb219-2"></a>P2 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,n)</span>
<span id="cb219-3"><a href="dondes.html#cb219-3"></a>P2[Y<span class="op">==</span><span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="kw">sum</span>(Y<span class="op">==</span><span class="dv">1</span>),<span class="dv">1</span>,<span class="fl">0.85</span>) </span>
<span id="cb219-4"><a href="dondes.html#cb219-4"></a>P2[Y<span class="op">==</span><span class="dv">0</span>] &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="kw">sum</span>(Y<span class="op">==</span><span class="dv">0</span>),<span class="dv">1</span>,<span class="fl">0.1</span>)  </span>
<span id="cb219-5"><a href="dondes.html#cb219-5"></a>P2 &lt;-<span class="st"> </span><span class="kw">factor</span>(P2,<span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;0&quot;</span>,<span class="st">&quot;1&quot;</span>))</span></code></pre></div></li>
<li><p>Dresser les tables de contingence de <strong>P1</strong> et <strong>P2</strong> à l’aide de <strong>table</strong>. Commenter.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="dondes.html#cb220-1"></a><span class="kw">table</span>(P1,Y)</span>
<span id="cb220-2"><a href="dondes.html#cb220-2"></a>   Y</span>
<span id="cb220-3"><a href="dondes.html#cb220-3"></a>P1    <span class="dv">0</span>   <span class="dv">1</span></span>
<span id="cb220-4"><a href="dondes.html#cb220-4"></a>  <span class="dv">0</span> <span class="dv">471</span>  <span class="dv">23</span></span>
<span id="cb220-5"><a href="dondes.html#cb220-5"></a>  <span class="dv">1</span>   <span class="dv">5</span>   <span class="dv">1</span></span>
<span id="cb220-6"><a href="dondes.html#cb220-6"></a><span class="kw">table</span>(P2,Y)</span>
<span id="cb220-7"><a href="dondes.html#cb220-7"></a>   Y</span>
<span id="cb220-8"><a href="dondes.html#cb220-8"></a>P2    <span class="dv">0</span>   <span class="dv">1</span></span>
<span id="cb220-9"><a href="dondes.html#cb220-9"></a>  <span class="dv">0</span> <span class="dv">432</span>   <span class="dv">8</span></span>
<span id="cb220-10"><a href="dondes.html#cb220-10"></a>  <span class="dv">1</span>  <span class="dv">44</span>  <span class="dv">16</span></span></code></pre></div>
<div class="corR">
<p>
On remarque que <strong>P1</strong> a tendance à prédire très souvent 0 (la classe majoritaire) alors que <strong>P2</strong> est capable d’identifier plus d’invididus de la petite classe. Du point de vue de l’<strong>accuracy</strong> on va privilégier <strong>P1</strong>, néanmoins dans de nombreux cas <strong>P2</strong> est plus pertinent.
</p>
</div></li>
<li><p>Pour <strong>P2</strong>, calculer, avec les fonctions usuelles de <code>R</code>, l’<strong>accuracy</strong>, le <strong>recall</strong> et la <strong>précision</strong>.</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="dondes.html#cb221-1"></a>T2 &lt;-<span class="st"> </span><span class="kw">table</span>(P2,Y)</span>
<span id="cb221-2"><a href="dondes.html#cb221-2"></a>acc &lt;-<span class="st"> </span><span class="kw">sum</span>(T2[<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">4</span>)])<span class="op">/</span><span class="kw">sum</span>(T2)</span>
<span id="cb221-3"><a href="dondes.html#cb221-3"></a>rec &lt;-<span class="st"> </span>T2[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">/</span><span class="kw">sum</span>(T2[,<span class="dv">2</span>])</span>
<span id="cb221-4"><a href="dondes.html#cb221-4"></a>prec &lt;-<span class="st"> </span>T2[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">/</span><span class="kw">sum</span>(T2[<span class="dv">2</span>,])</span></code></pre></div>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="dondes.html#cb222-1"></a><span class="kw">c</span>(acc,rec,prec)</span>
<span id="cb222-2"><a href="dondes.html#cb222-2"></a>[<span class="dv">1</span>] <span class="fl">0.8960000</span> <span class="fl">0.6666667</span> <span class="fl">0.2666667</span></span></code></pre></div></li>
<li><p>En déduire le F1-score.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="dondes.html#cb223-1"></a>F1 &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">*</span>(rec<span class="op">*</span>prec)<span class="op">/</span>(rec<span class="op">+</span>prec)</span>
<span id="cb223-2"><a href="dondes.html#cb223-2"></a>F1</span>
<span id="cb223-3"><a href="dondes.html#cb223-3"></a>[<span class="dv">1</span>] <span class="fl">0.3809524</span></span></code></pre></div></li>
<li><p>Même question pour le <span class="math inline">\(\kappa\)</span> de Cohen.</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="dondes.html#cb224-1"></a>rand &lt;-<span class="st"> </span><span class="kw">sum</span>(T2[<span class="dv">1</span>,])<span class="op">/</span>n<span class="op">*</span><span class="kw">sum</span>(T2[,<span class="dv">1</span>])<span class="op">/</span>n<span class="op">+</span><span class="kw">sum</span>(T2[<span class="dv">2</span>,])<span class="op">/</span>n<span class="op">*</span><span class="kw">sum</span>(T2[,<span class="dv">2</span>])<span class="op">/</span>n</span>
<span id="cb224-2"><a href="dondes.html#cb224-2"></a>kappa &lt;-<span class="st"> </span>(acc<span class="op">-</span>rand)<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>rand)</span>
<span id="cb224-3"><a href="dondes.html#cb224-3"></a>kappa</span>
<span id="cb224-4"><a href="dondes.html#cb224-4"></a>[<span class="dv">1</span>] <span class="fl">0.3353783</span></span></code></pre></div></li>
<li><p>Retrouver ces indicateurs à l’aide de la fonction <strong>confusionMatrix</strong> de <strong>caret</strong> puis comparer les prévisions <strong>P1</strong> et <strong>P2</strong>.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="dondes.html#cb225-1"></a><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>P1,<span class="dt">reference=</span>Y,<span class="dt">mode=</span><span class="st">&quot;everything&quot;</span>,<span class="dt">positive=</span><span class="st">&quot;1&quot;</span>)</span>
<span id="cb225-2"><a href="dondes.html#cb225-2"></a>Confusion Matrix and Statistics</span>
<span id="cb225-3"><a href="dondes.html#cb225-3"></a></span>
<span id="cb225-4"><a href="dondes.html#cb225-4"></a>          Reference</span>
<span id="cb225-5"><a href="dondes.html#cb225-5"></a>Prediction   <span class="dv">0</span>   <span class="dv">1</span></span>
<span id="cb225-6"><a href="dondes.html#cb225-6"></a>         <span class="dv">0</span> <span class="dv">471</span>  <span class="dv">23</span></span>
<span id="cb225-7"><a href="dondes.html#cb225-7"></a>         <span class="dv">1</span>   <span class="dv">5</span>   <span class="dv">1</span></span>
<span id="cb225-8"><a href="dondes.html#cb225-8"></a></span>
<span id="cb225-9"><a href="dondes.html#cb225-9"></a>               Accuracy <span class="op">:</span><span class="st"> </span><span class="fl">0.944</span>           </span>
<span id="cb225-10"><a href="dondes.html#cb225-10"></a>                 <span class="dv">95</span>% CI <span class="op">:</span><span class="st"> </span>(<span class="fl">0.9201</span>, <span class="fl">0.9625</span>)</span>
<span id="cb225-11"><a href="dondes.html#cb225-11"></a>    No Information Rate <span class="op">:</span><span class="st"> </span><span class="fl">0.952</span>           </span>
<span id="cb225-12"><a href="dondes.html#cb225-12"></a>    P<span class="op">-</span>Value [Acc <span class="op">&gt;</span><span class="st"> </span>NIR] <span class="op">:</span><span class="st"> </span><span class="fl">0.827961</span>        </span>
<span id="cb225-13"><a href="dondes.html#cb225-13"></a></span>
<span id="cb225-14"><a href="dondes.html#cb225-14"></a>                  Kappa <span class="op">:</span><span class="st"> </span><span class="fl">0.0484</span>          </span>
<span id="cb225-15"><a href="dondes.html#cb225-15"></a></span>
<span id="cb225-16"><a href="dondes.html#cb225-16"></a> Mcnemar<span class="st">&#39;s Test P-Value : 0.001315        </span></span>
<span id="cb225-17"><a href="dondes.html#cb225-17"></a></span>
<span id="cb225-18"><a href="dondes.html#cb225-18"></a><span class="st">            Sensitivity : 0.04167         </span></span>
<span id="cb225-19"><a href="dondes.html#cb225-19"></a><span class="st">            Specificity : 0.98950         </span></span>
<span id="cb225-20"><a href="dondes.html#cb225-20"></a><span class="st">         Pos Pred Value : 0.16667         </span></span>
<span id="cb225-21"><a href="dondes.html#cb225-21"></a><span class="st">         Neg Pred Value : 0.95344         </span></span>
<span id="cb225-22"><a href="dondes.html#cb225-22"></a><span class="st">              Precision : 0.16667         </span></span>
<span id="cb225-23"><a href="dondes.html#cb225-23"></a><span class="st">                 Recall : 0.04167         </span></span>
<span id="cb225-24"><a href="dondes.html#cb225-24"></a><span class="st">                     F1 : 0.06667         </span></span>
<span id="cb225-25"><a href="dondes.html#cb225-25"></a><span class="st">             Prevalence : 0.04800         </span></span>
<span id="cb225-26"><a href="dondes.html#cb225-26"></a><span class="st">         Detection Rate : 0.00200         </span></span>
<span id="cb225-27"><a href="dondes.html#cb225-27"></a><span class="st">   Detection Prevalence : 0.01200         </span></span>
<span id="cb225-28"><a href="dondes.html#cb225-28"></a><span class="st">      Balanced Accuracy : 0.51558         </span></span>
<span id="cb225-29"><a href="dondes.html#cb225-29"></a></span>
<span id="cb225-30"><a href="dondes.html#cb225-30"></a><span class="st">       &#39;</span>Positive<span class="st">&#39; Class : 1               </span></span>
<span id="cb225-31"><a href="dondes.html#cb225-31"></a></span>
<span id="cb225-32"><a href="dondes.html#cb225-32"></a><span class="st">confusionMatrix(data=P2,reference=Y,mode=&quot;everything&quot;,positive=&quot;1&quot;)</span></span>
<span id="cb225-33"><a href="dondes.html#cb225-33"></a><span class="st">Confusion Matrix and Statistics</span></span>
<span id="cb225-34"><a href="dondes.html#cb225-34"></a></span>
<span id="cb225-35"><a href="dondes.html#cb225-35"></a><span class="st">          Reference</span></span>
<span id="cb225-36"><a href="dondes.html#cb225-36"></a><span class="st">Prediction   0   1</span></span>
<span id="cb225-37"><a href="dondes.html#cb225-37"></a><span class="st">         0 432   8</span></span>
<span id="cb225-38"><a href="dondes.html#cb225-38"></a><span class="st">         1  44  16</span></span>
<span id="cb225-39"><a href="dondes.html#cb225-39"></a></span>
<span id="cb225-40"><a href="dondes.html#cb225-40"></a><span class="st">               Accuracy : 0.896           </span></span>
<span id="cb225-41"><a href="dondes.html#cb225-41"></a><span class="st">                 95% CI : (0.8659, 0.9213)</span></span>
<span id="cb225-42"><a href="dondes.html#cb225-42"></a><span class="st">    No Information Rate : 0.952           </span></span>
<span id="cb225-43"><a href="dondes.html#cb225-43"></a><span class="st">    P-Value [Acc &gt; NIR] : 1               </span></span>
<span id="cb225-44"><a href="dondes.html#cb225-44"></a></span>
<span id="cb225-45"><a href="dondes.html#cb225-45"></a><span class="st">                  Kappa : 0.3354          </span></span>
<span id="cb225-46"><a href="dondes.html#cb225-46"></a></span>
<span id="cb225-47"><a href="dondes.html#cb225-47"></a><span class="st"> Mcnemar&#39;</span>s Test P<span class="op">-</span>Value <span class="op">:</span><span class="st"> </span><span class="fl">1.212e-06</span>       </span>
<span id="cb225-48"><a href="dondes.html#cb225-48"></a></span>
<span id="cb225-49"><a href="dondes.html#cb225-49"></a>            Sensitivity <span class="op">:</span><span class="st"> </span><span class="fl">0.6667</span>          </span>
<span id="cb225-50"><a href="dondes.html#cb225-50"></a>            Specificity <span class="op">:</span><span class="st"> </span><span class="fl">0.9076</span>          </span>
<span id="cb225-51"><a href="dondes.html#cb225-51"></a>         Pos Pred Value <span class="op">:</span><span class="st"> </span><span class="fl">0.2667</span>          </span>
<span id="cb225-52"><a href="dondes.html#cb225-52"></a>         Neg Pred Value <span class="op">:</span><span class="st"> </span><span class="fl">0.9818</span>          </span>
<span id="cb225-53"><a href="dondes.html#cb225-53"></a>              Precision <span class="op">:</span><span class="st"> </span><span class="fl">0.2667</span>          </span>
<span id="cb225-54"><a href="dondes.html#cb225-54"></a>                 Recall <span class="op">:</span><span class="st"> </span><span class="fl">0.6667</span>          </span>
<span id="cb225-55"><a href="dondes.html#cb225-55"></a>                     F1 <span class="op">:</span><span class="st"> </span><span class="fl">0.3810</span>          </span>
<span id="cb225-56"><a href="dondes.html#cb225-56"></a>             Prevalence <span class="op">:</span><span class="st"> </span><span class="fl">0.0480</span>          </span>
<span id="cb225-57"><a href="dondes.html#cb225-57"></a>         Detection Rate <span class="op">:</span><span class="st"> </span><span class="fl">0.0320</span>          </span>
<span id="cb225-58"><a href="dondes.html#cb225-58"></a>   Detection Prevalence <span class="op">:</span><span class="st"> </span><span class="fl">0.1200</span>          </span>
<span id="cb225-59"><a href="dondes.html#cb225-59"></a>      Balanced Accuracy <span class="op">:</span><span class="st"> </span><span class="fl">0.7871</span>          </span>
<span id="cb225-60"><a href="dondes.html#cb225-60"></a></span>
<span id="cb225-61"><a href="dondes.html#cb225-61"></a>       <span class="st">&#39;Positive&#39;</span> Class <span class="op">:</span><span class="st"> </span><span class="dv">1</span>               </span></code></pre></div>
<div class="corR">
<p>
L’<strong>accuracy</strong> privilégie clairement <strong>P1</strong> alors que d’autres critères comme le <strong>balanced accuracy</strong>, le <strong>F1-score</strong> ou le <strong>kappa de Cohen</strong> vont sélectionner <strong>P2</strong>. Ces derniers critères sont mieux adaptés pour prendre en considération la capacité à bien identifier la classe minoritaire.
</p>
</div></li>
</ol>
</div>
<div id="ré-équilibrage" class="section level2">
<h2><span class="header-section-number">7.2</span> Ré-équilibrage</h2>
<p>En complément du choix d’un <strong>critère pertinent</strong>, il peut être intéressant de tenter de <strong>ré-équilibrer</strong> l’échantillon pour aider les algorithmes à mieux <strong>détecter les individus de la classe minoritaire</strong>. Les méthodes classiques consistent à créer de nouvelles observations de la classe minoritaire (<strong>oversampling</strong>) et/ou supprimer des individus de la classe minoritaire (<strong>undersampling</strong>).</p>

<div class="exercise">
<span id="exr:exo-dondes-comp-reeq" class="exercise"><strong>Exercice 7.2  (Quelques algorithmes de ré-équilibrage)  </strong></span>
</div>

<p>On considère le jeu de données <code>df</code> ci-dessous où on cherche à prédire <code>Y</code> par <code>X1</code> et <code>X2</code>.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="dondes.html#cb226-1"></a>n &lt;-<span class="st"> </span><span class="dv">2000</span></span>
<span id="cb226-2"><a href="dondes.html#cb226-2"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb226-3"><a href="dondes.html#cb226-3"></a>X1 &lt;-<span class="st"> </span><span class="kw">runif</span>(n)</span>
<span id="cb226-4"><a href="dondes.html#cb226-4"></a><span class="kw">set.seed</span>(<span class="dv">5678</span>)</span>
<span id="cb226-5"><a href="dondes.html#cb226-5"></a>X2 &lt;-<span class="st"> </span><span class="kw">runif</span>(n)</span>
<span id="cb226-6"><a href="dondes.html#cb226-6"></a><span class="kw">set.seed</span>(<span class="dv">9012</span>)</span>
<span id="cb226-7"><a href="dondes.html#cb226-7"></a>R1 &lt;-<span class="st"> </span>X1<span class="op">&lt;=</span><span class="fl">0.25</span></span>
<span id="cb226-8"><a href="dondes.html#cb226-8"></a>R2 &lt;-<span class="st"> </span>(X1<span class="op">&gt;</span><span class="fl">0.25</span> <span class="op">&amp;</span><span class="st"> </span>X2<span class="op">&gt;=</span><span class="fl">0.75</span>)</span>
<span id="cb226-9"><a href="dondes.html#cb226-9"></a>R3 &lt;-<span class="st"> </span>(X1<span class="op">&gt;</span><span class="fl">0.25</span> <span class="op">&amp;</span><span class="st"> </span>X2<span class="op">&lt;</span><span class="fl">0.75</span>)</span>
<span id="cb226-10"><a href="dondes.html#cb226-10"></a>Y &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,n)</span>
<span id="cb226-11"><a href="dondes.html#cb226-11"></a>Y[R1] &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="kw">sum</span>(R1),<span class="dv">1</span>,<span class="fl">0.75</span>)</span>
<span id="cb226-12"><a href="dondes.html#cb226-12"></a>Y[R2] &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="kw">sum</span>(R2),<span class="dv">1</span>,<span class="fl">0.75</span>)</span>
<span id="cb226-13"><a href="dondes.html#cb226-13"></a>Y[R3] &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="kw">sum</span>(R3),<span class="dv">1</span>,<span class="fl">0.25</span>)</span>
<span id="cb226-14"><a href="dondes.html#cb226-14"></a>df1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(X1,X2,Y)</span>
<span id="cb226-15"><a href="dondes.html#cb226-15"></a>df1<span class="op">$</span>Y &lt;-<span class="st"> </span><span class="kw">factor</span>(df1<span class="op">$</span>Y)</span>
<span id="cb226-16"><a href="dondes.html#cb226-16"></a>indDY1 &lt;-<span class="st"> </span><span class="kw">which</span>(df1<span class="op">$</span>Y<span class="op">==</span><span class="dv">1</span>)</span>
<span id="cb226-17"><a href="dondes.html#cb226-17"></a>df1<span class="fl">.1</span> &lt;-<span class="st"> </span>df1[<span class="op">-</span>indDY1[<span class="dv">1</span><span class="op">:</span><span class="dv">650</span>],]</span>
<span id="cb226-18"><a href="dondes.html#cb226-18"></a>df1<span class="fl">.2</span> &lt;-<span class="st"> </span>df1<span class="fl">.1</span>[<span class="kw">sample</span>(<span class="kw">nrow</span>(df1<span class="fl">.1</span>),<span class="dv">1000</span>),]</span>
<span id="cb226-19"><a href="dondes.html#cb226-19"></a>df &lt;-<span class="st"> </span>df1<span class="fl">.2</span>[<span class="kw">sample</span>(<span class="kw">nrow</span>(df1<span class="fl">.2</span>),<span class="dv">100</span>),]</span>
<span id="cb226-20"><a href="dondes.html#cb226-20"></a><span class="kw">rownames</span>(df) &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb226-21"><a href="dondes.html#cb226-21"></a>p1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(df)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>X1,<span class="dt">y=</span>X2,<span class="dt">color=</span>Y)<span class="op">+</span><span class="kw">geom_point</span>()</span>
<span id="cb226-22"><a href="dondes.html#cb226-22"></a>p1</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-347-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>On a ici 4 fois plus d’observations dans le groupe 0.</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="dondes.html#cb227-1"></a><span class="kw">summary</span>(df<span class="op">$</span>Y)</span>
<span id="cb227-2"><a href="dondes.html#cb227-2"></a> <span class="dv">0</span>  <span class="dv">1</span> </span>
<span id="cb227-3"><a href="dondes.html#cb227-3"></a><span class="dv">80</span> <span class="dv">20</span> </span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>On commence par faire du <strong>oversampling</strong> avec la fonction <code>RandOverClassif</code>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Effectuer le ré-échantillonnage et expliquer.</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="dondes.html#cb228-1"></a><span class="kw">library</span>(UBL)</span>
<span id="cb228-2"><a href="dondes.html#cb228-2"></a>over1 &lt;-<span class="st"> </span><span class="kw">RandOverClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat =</span> df)</span>
<span id="cb228-3"><a href="dondes.html#cb228-3"></a><span class="kw">summary</span>(over1<span class="op">$</span>Y)</span>
<span id="cb228-4"><a href="dondes.html#cb228-4"></a> <span class="dv">0</span>  <span class="dv">1</span> </span>
<span id="cb228-5"><a href="dondes.html#cb228-5"></a><span class="dv">80</span> <span class="dv">80</span> </span></code></pre></div>
<div class="corR">
<p>
On duplique des observations du groupe 1 pour atteindre le nombre d’observations du groupe 0.
</p>
</div></li>
<li><p>Corriger les paramètres de la fonction de manière à avoir 80 observations dans le groupe 0 et 60 dans le groupe 1.</p>
<div class="corR">
<p>
Il suffit de laisser intact le groupe 0 et de multiplier par 3 le nombre d’observations du groupe 1.
</p>
</div>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="dondes.html#cb229-1"></a><span class="kw">library</span>(UBL)</span>
<span id="cb229-2"><a href="dondes.html#cb229-2"></a>over2 &lt;-<span class="st"> </span><span class="kw">RandOverClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat =</span> df,<span class="dt">C.perc=</span><span class="kw">list</span>(<span class="st">&quot;0&quot;</span>=<span class="dv">1</span>,<span class="st">&quot;1&quot;</span>=<span class="dv">3</span>))</span>
<span id="cb229-3"><a href="dondes.html#cb229-3"></a><span class="kw">summary</span>(over2<span class="op">$</span>Y)</span>
<span id="cb229-4"><a href="dondes.html#cb229-4"></a> <span class="dv">0</span>  <span class="dv">1</span> </span>
<span id="cb229-5"><a href="dondes.html#cb229-5"></a><span class="dv">80</span> <span class="dv">60</span> </span></code></pre></div></li>
</ol></li>
<li><p>On s’intéresse maintenant à l’algorithme <strong>SMOTE</strong></p>
<ol style="list-style-type: lower-alpha">
<li><p>Exécuter la fonction <strong>SmoteClassif</strong> avec <code>k=3</code> et les les paramètres par défaut</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="dondes.html#cb230-1"></a>smote1 &lt;-<span class="st"> </span><span class="kw">SmoteClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>df,<span class="dt">k=</span><span class="dv">3</span>)</span>
<span id="cb230-2"><a href="dondes.html#cb230-2"></a><span class="kw">summary</span>(smote1<span class="op">$</span>Y)</span>
<span id="cb230-3"><a href="dondes.html#cb230-3"></a> <span class="dv">0</span>  <span class="dv">1</span> </span>
<span id="cb230-4"><a href="dondes.html#cb230-4"></a><span class="dv">50</span> <span class="dv">50</span> </span></code></pre></div>
<div class="corR">
<p>
30 observations ont été crées par l’algorithme <strong>SMOTE</strong>. On a également enlevé des observations du groupe 1 pour avoir autant d’observations dans les deux groupes.
</p>
</div></li>
<li><p>Visualiser les <strong>observations smote</strong>.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="dondes.html#cb231-1"></a>new &lt;-<span class="st"> </span><span class="kw">anti_join</span>(smote1,df)</span>
<span id="cb231-2"><a href="dondes.html#cb231-2"></a>old &lt;-<span class="st"> </span><span class="kw">inner_join</span>(smote1,df)</span>
<span id="cb231-3"><a href="dondes.html#cb231-3"></a><span class="kw">ggplot</span>(old)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>X1,<span class="dt">y=</span>X2)<span class="op">+</span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>Y))<span class="op">+</span></span>
<span id="cb231-4"><a href="dondes.html#cb231-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>new,<span class="dt">color=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-355-1.png" width="672" style="display: block; margin: auto;" /></p></li>
<li><p>Corriger les paramètres de la fonction de manière à avoir 80 observations dans le groupe 0 et 60 dans le groupe 1.</p>
<div class="corR">
<p>
Ici encore il “suffit” de jouer avec l’option <code>C.perc</code>.
</p>
</div>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="dondes.html#cb232-1"></a>smote2 &lt;-<span class="st"> </span><span class="kw">SmoteClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>df,<span class="dt">k=</span><span class="dv">3</span>,<span class="dt">C.perc=</span><span class="kw">list</span>(<span class="st">&quot;0&quot;</span>=<span class="dv">1</span>,<span class="st">&quot;1&quot;</span>=<span class="dv">3</span>))</span>
<span id="cb232-2"><a href="dondes.html#cb232-2"></a><span class="kw">summary</span>(smote2<span class="op">$</span>Y)</span>
<span id="cb232-3"><a href="dondes.html#cb232-3"></a> <span class="dv">0</span>  <span class="dv">1</span> </span>
<span id="cb232-4"><a href="dondes.html#cb232-4"></a><span class="dv">80</span> <span class="dv">60</span> </span></code></pre></div></li>
</ol></li>
<li><p>On souhaite maintenant ré-équilibrer par <strong>random undersampling</strong>. Utiliser la fonction <strong>RandUnderClassif</strong> pour effectuer un tel ré-équilibrage. Ici encore on pourra faire varier les paramètres.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="dondes.html#cb233-1"></a>under1 &lt;-<span class="st"> </span><span class="kw">RandUnderClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>df)</span>
<span id="cb233-2"><a href="dondes.html#cb233-2"></a><span class="kw">summary</span>(under1)</span>
<span id="cb233-3"><a href="dondes.html#cb233-3"></a>       X1                X2           Y     </span>
<span id="cb233-4"><a href="dondes.html#cb233-4"></a> Min.   <span class="op">:</span><span class="fl">0.01288</span>   Min.   <span class="op">:</span><span class="fl">0.006945</span>   <span class="dv">0</span><span class="op">:</span><span class="dv">20</span>  </span>
<span id="cb233-5"><a href="dondes.html#cb233-5"></a> 1st Qu.<span class="op">:</span><span class="fl">0.23283</span>   1st Qu.<span class="op">:</span><span class="fl">0.277733</span>   <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>  </span>
<span id="cb233-6"><a href="dondes.html#cb233-6"></a> Median <span class="op">:</span><span class="fl">0.38112</span>   Median <span class="op">:</span><span class="fl">0.525170</span>         </span>
<span id="cb233-7"><a href="dondes.html#cb233-7"></a> Mean   <span class="op">:</span><span class="fl">0.42021</span>   Mean   <span class="op">:</span><span class="fl">0.512639</span>         </span>
<span id="cb233-8"><a href="dondes.html#cb233-8"></a> 3rd Qu.<span class="op">:</span><span class="fl">0.54655</span>   3rd Qu.<span class="op">:</span><span class="fl">0.740836</span>         </span>
<span id="cb233-9"><a href="dondes.html#cb233-9"></a> Max.   <span class="op">:</span><span class="fl">0.96958</span>   Max.   <span class="op">:</span><span class="fl">0.999183</span>         </span></code></pre></div>
<div class="corR">
<p>
On supprimer des obseravtions du groupe 0 pour avoir le même nombre d’observations dans les deux groupes. Ici encore on peut contrôler le niveau de ré-équilibrage avec <code>C.perc</code> :
</p>
</div>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="dondes.html#cb234-1"></a>under2 &lt;-<span class="st"> </span><span class="kw">RandUnderClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>df,<span class="dt">C.perc =</span> <span class="kw">list</span>(<span class="st">&quot;0&quot;</span>=<span class="fl">0.5</span>,<span class="st">&quot;1&quot;</span>=<span class="dv">1</span>))</span>
<span id="cb234-2"><a href="dondes.html#cb234-2"></a><span class="kw">summary</span>(under2<span class="op">$</span>Y)</span>
<span id="cb234-3"><a href="dondes.html#cb234-3"></a> <span class="dv">0</span>  <span class="dv">1</span> </span>
<span id="cb234-4"><a href="dondes.html#cb234-4"></a><span class="dv">40</span> <span class="dv">20</span> </span></code></pre></div></li>
<li><p>On passe maintenant à l’algorithme <strong>Tomek</strong>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Sans utiliser la fonction <strong>TomekClassif</strong> identifier les paires d’observations qui ont un <strong>lien de Tomek</strong>. On pourra utiliser la fonction <strong>nng</strong> du package <code>cccd</code>.</p>
<div class="corR">
<p>
On rappelle que deux observations ont un lien de Tomek si elles sont plus proches voisins mutuels et de deux groupes différents. On commence donc par identifier les plus proches voisins mutuels :
</p>
</div>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="dondes.html#cb235-1"></a><span class="kw">library</span>(cccd)</span>
<span id="cb235-2"><a href="dondes.html#cb235-2"></a>unppv &lt;-<span class="st"> </span><span class="kw">nng</span>(<span class="dt">x=</span>df[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">k=</span><span class="dv">1</span>,<span class="dt">mutual=</span><span class="ot">TRUE</span>)</span>
<span id="cb235-3"><a href="dondes.html#cb235-3"></a>graph_mut &lt;-<span class="st"> </span><span class="kw">as_data_frame</span>(unppv)</span>
<span id="cb235-4"><a href="dondes.html#cb235-4"></a>graph_mut</span>
<span id="cb235-5"><a href="dondes.html#cb235-5"></a>   from  to</span>
<span id="cb235-6"><a href="dondes.html#cb235-6"></a><span class="dv">1</span>     <span class="dv">1</span>  <span class="dv">13</span></span>
<span id="cb235-7"><a href="dondes.html#cb235-7"></a><span class="dv">2</span>     <span class="dv">2</span>  <span class="dv">50</span></span>
<span id="cb235-8"><a href="dondes.html#cb235-8"></a><span class="dv">3</span>     <span class="dv">3</span>  <span class="dv">54</span></span>
<span id="cb235-9"><a href="dondes.html#cb235-9"></a><span class="dv">4</span>     <span class="dv">4</span>  <span class="dv">98</span></span>
<span id="cb235-10"><a href="dondes.html#cb235-10"></a><span class="dv">5</span>     <span class="dv">5</span>  <span class="dv">42</span></span>
<span id="cb235-11"><a href="dondes.html#cb235-11"></a><span class="dv">6</span>     <span class="dv">6</span>  <span class="dv">35</span></span>
<span id="cb235-12"><a href="dondes.html#cb235-12"></a><span class="dv">7</span>     <span class="dv">9</span>  <span class="dv">96</span></span>
<span id="cb235-13"><a href="dondes.html#cb235-13"></a><span class="dv">8</span>    <span class="dv">12</span>  <span class="dv">30</span></span>
<span id="cb235-14"><a href="dondes.html#cb235-14"></a><span class="dv">9</span>    <span class="dv">16</span>  <span class="dv">41</span></span>
<span id="cb235-15"><a href="dondes.html#cb235-15"></a><span class="dv">10</span>   <span class="dv">18</span> <span class="dv">100</span></span>
<span id="cb235-16"><a href="dondes.html#cb235-16"></a><span class="dv">11</span>   <span class="dv">19</span>  <span class="dv">44</span></span>
<span id="cb235-17"><a href="dondes.html#cb235-17"></a><span class="dv">12</span>   <span class="dv">20</span>  <span class="dv">92</span></span>
<span id="cb235-18"><a href="dondes.html#cb235-18"></a><span class="dv">13</span>   <span class="dv">24</span>  <span class="dv">28</span></span>
<span id="cb235-19"><a href="dondes.html#cb235-19"></a><span class="dv">14</span>   <span class="dv">26</span>  <span class="dv">87</span></span>
<span id="cb235-20"><a href="dondes.html#cb235-20"></a><span class="dv">15</span>   <span class="dv">27</span>  <span class="dv">91</span></span>
<span id="cb235-21"><a href="dondes.html#cb235-21"></a><span class="dv">16</span>   <span class="dv">29</span>  <span class="dv">64</span></span>
<span id="cb235-22"><a href="dondes.html#cb235-22"></a><span class="dv">17</span>   <span class="dv">31</span>  <span class="dv">82</span></span>
<span id="cb235-23"><a href="dondes.html#cb235-23"></a><span class="dv">18</span>   <span class="dv">32</span>  <span class="dv">94</span></span>
<span id="cb235-24"><a href="dondes.html#cb235-24"></a><span class="dv">19</span>   <span class="dv">33</span>  <span class="dv">69</span></span>
<span id="cb235-25"><a href="dondes.html#cb235-25"></a><span class="dv">20</span>   <span class="dv">36</span>  <span class="dv">68</span></span>
<span id="cb235-26"><a href="dondes.html#cb235-26"></a><span class="dv">21</span>   <span class="dv">37</span>  <span class="dv">99</span></span>
<span id="cb235-27"><a href="dondes.html#cb235-27"></a><span class="dv">22</span>   <span class="dv">40</span>  <span class="dv">62</span></span>
<span id="cb235-28"><a href="dondes.html#cb235-28"></a><span class="dv">23</span>   <span class="dv">45</span>  <span class="dv">55</span></span>
<span id="cb235-29"><a href="dondes.html#cb235-29"></a><span class="dv">24</span>   <span class="dv">48</span>  <span class="dv">51</span></span>
<span id="cb235-30"><a href="dondes.html#cb235-30"></a><span class="dv">25</span>   <span class="dv">52</span>  <span class="dv">66</span></span>
<span id="cb235-31"><a href="dondes.html#cb235-31"></a><span class="dv">26</span>   <span class="dv">56</span>  <span class="dv">58</span></span>
<span id="cb235-32"><a href="dondes.html#cb235-32"></a><span class="dv">27</span>   <span class="dv">65</span>  <span class="dv">75</span></span>
<span id="cb235-33"><a href="dondes.html#cb235-33"></a><span class="dv">28</span>   <span class="dv">67</span>  <span class="dv">77</span></span>
<span id="cb235-34"><a href="dondes.html#cb235-34"></a><span class="dv">29</span>   <span class="dv">72</span>  <span class="dv">86</span></span>
<span id="cb235-35"><a href="dondes.html#cb235-35"></a><span class="dv">30</span>   <span class="dv">73</span>  <span class="dv">93</span></span>
<span id="cb235-36"><a href="dondes.html#cb235-36"></a><span class="dv">31</span>   <span class="dv">74</span>  <span class="dv">89</span></span></code></pre></div>
<div class="corR">
<p>
Puis on récupère les groupes de ces observations afin de ne conserver que les paires qui proviennent de groupes différents :
</p>
</div>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="dondes.html#cb236-1"></a>Yfrom &lt;-<span class="st"> </span>df<span class="op">$</span>Y[graph_mut<span class="op">$</span>from]</span>
<span id="cb236-2"><a href="dondes.html#cb236-2"></a>Yto &lt;-<span class="st"> </span>df<span class="op">$</span>Y[graph_mut<span class="op">$</span>to]</span>
<span id="cb236-3"><a href="dondes.html#cb236-3"></a>tomek_link &lt;-<span class="st"> </span>graph_mut <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Yfrom<span class="op">!=</span>Yto)</span>
<span id="cb236-4"><a href="dondes.html#cb236-4"></a>tomek_link</span>
<span id="cb236-5"><a href="dondes.html#cb236-5"></a>  from  to</span>
<span id="cb236-6"><a href="dondes.html#cb236-6"></a><span class="dv">1</span>    <span class="dv">4</span>  <span class="dv">98</span></span>
<span id="cb236-7"><a href="dondes.html#cb236-7"></a><span class="dv">2</span>   <span class="dv">16</span>  <span class="dv">41</span></span>
<span id="cb236-8"><a href="dondes.html#cb236-8"></a><span class="dv">3</span>   <span class="dv">18</span> <span class="dv">100</span></span>
<span id="cb236-9"><a href="dondes.html#cb236-9"></a><span class="dv">4</span>   <span class="dv">19</span>  <span class="dv">44</span></span>
<span id="cb236-10"><a href="dondes.html#cb236-10"></a><span class="dv">5</span>   <span class="dv">26</span>  <span class="dv">87</span></span>
<span id="cb236-11"><a href="dondes.html#cb236-11"></a><span class="dv">6</span>   <span class="dv">29</span>  <span class="dv">64</span></span>
<span id="cb236-12"><a href="dondes.html#cb236-12"></a><span class="dv">7</span>   <span class="dv">45</span>  <span class="dv">55</span></span>
<span id="cb236-13"><a href="dondes.html#cb236-13"></a><span class="dv">8</span>   <span class="dv">72</span>  <span class="dv">86</span></span>
<span id="cb236-14"><a href="dondes.html#cb236-14"></a><span class="dv">9</span>   <span class="dv">74</span>  <span class="dv">89</span></span></code></pre></div></li>
<li><p>Retrouver ces paires à l’aide de la fonction Tomek LinK.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="dondes.html#cb237-1"></a>tomek1 &lt;-<span class="st"> </span><span class="kw">TomekClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>df)</span>
<span id="cb237-2"><a href="dondes.html#cb237-2"></a>tomek1[[<span class="dv">2</span>]]</span>
<span id="cb237-3"><a href="dondes.html#cb237-3"></a> [<span class="dv">1</span>]   <span class="dv">4</span>  <span class="dv">98</span>  <span class="dv">16</span>  <span class="dv">41</span>  <span class="dv">18</span> <span class="dv">100</span>  <span class="dv">19</span>  <span class="dv">44</span>  <span class="dv">26</span>  <span class="dv">87</span>  <span class="dv">29</span>  <span class="dv">64</span>  <span class="dv">45</span>  <span class="dv">55</span></span>
<span id="cb237-4"><a href="dondes.html#cb237-4"></a>[<span class="dv">15</span>]  <span class="dv">72</span>  <span class="dv">86</span>  <span class="dv">74</span>  <span class="dv">89</span></span></code></pre></div></li>
<li><p>Visualiser les observations supprimées. On prendra soin d’expliquer l’option <code>rem</code> de <strong>TomekClassif</strong>.</p>
<div class="corR">
<p>
On dispose de deux stratégies. On peut enlever les paires entières qui sont <strong>T-link</strong> avec l’option par défaut
</p>
</div>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="dondes.html#cb238-1"></a><span class="kw">ggplot</span>(tomek1[[<span class="dv">1</span>]])<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>X1,<span class="dt">y=</span>X2,<span class="dt">color=</span>Y)<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span></span>
<span id="cb238-2"><a href="dondes.html#cb238-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>df[tomek1[[<span class="dv">2</span>]],],<span class="dt">shape=</span><span class="dv">17</span>,<span class="dt">size=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-367-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
On peut également ne supprimer que l’élelément du <strong>T-link</strong> du groupe majoritaire avec l’option <code>rem=“maj”</code> :
</p>
</div>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="dondes.html#cb239-1"></a>tomek2 &lt;-<span class="st"> </span><span class="kw">TomekClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>df,<span class="dt">rem=</span><span class="st">&quot;maj&quot;</span>)</span>
<span id="cb239-2"><a href="dondes.html#cb239-2"></a>tomek2[[<span class="dv">2</span>]]</span>
<span id="cb239-3"><a href="dondes.html#cb239-3"></a>[<span class="dv">1</span>]   <span class="dv">4</span>  <span class="dv">41</span> <span class="dv">100</span>  <span class="dv">19</span>  <span class="dv">87</span>  <span class="dv">29</span>  <span class="dv">55</span>  <span class="dv">86</span>  <span class="dv">89</span></span>
<span id="cb239-4"><a href="dondes.html#cb239-4"></a><span class="kw">ggplot</span>(tomek2[[<span class="dv">1</span>]])<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>X1,<span class="dt">y=</span>X2,<span class="dt">color=</span>Y)<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span></span>
<span id="cb239-5"><a href="dondes.html#cb239-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>df[tomek2[[<span class="dv">2</span>]],],<span class="dt">shape=</span><span class="dv">17</span>,<span class="dt">size=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-369-1.png" width="672" style="display: block; margin: auto;" /></p></li>
</ol></li>
</ol>

<div class="exercise">
<span id="exr:exo-dondes-comp-reeq" class="exercise"><strong>Exercice 7.2  (Comparaison de méthodes de ré-équilibrage)  </strong></span>
</div>

<p>On considère 3 jeux de données <code>df1</code>, <code>df2</code> et <code>df3</code>.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="dondes.html#cb240-1"></a>n &lt;-<span class="st"> </span><span class="dv">2000</span></span>
<span id="cb240-2"><a href="dondes.html#cb240-2"></a><span class="kw">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb240-3"><a href="dondes.html#cb240-3"></a>X1 &lt;-<span class="st"> </span><span class="kw">runif</span>(n)</span>
<span id="cb240-4"><a href="dondes.html#cb240-4"></a><span class="kw">set.seed</span>(<span class="dv">5678</span>)</span>
<span id="cb240-5"><a href="dondes.html#cb240-5"></a>X2 &lt;-<span class="st"> </span><span class="kw">runif</span>(n)</span>
<span id="cb240-6"><a href="dondes.html#cb240-6"></a><span class="kw">set.seed</span>(<span class="dv">9012</span>)</span>
<span id="cb240-7"><a href="dondes.html#cb240-7"></a>R1 &lt;-<span class="st"> </span>X1<span class="op">&lt;=</span><span class="fl">0.25</span></span>
<span id="cb240-8"><a href="dondes.html#cb240-8"></a>R2 &lt;-<span class="st"> </span>(X1<span class="op">&gt;</span><span class="fl">0.25</span> <span class="op">&amp;</span><span class="st"> </span>X2<span class="op">&gt;=</span><span class="fl">0.75</span>)</span>
<span id="cb240-9"><a href="dondes.html#cb240-9"></a>R3 &lt;-<span class="st"> </span>(X1<span class="op">&gt;</span><span class="fl">0.25</span> <span class="op">&amp;</span><span class="st"> </span>X2<span class="op">&lt;</span><span class="fl">0.75</span>)</span>
<span id="cb240-10"><a href="dondes.html#cb240-10"></a>Y &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,n)</span>
<span id="cb240-11"><a href="dondes.html#cb240-11"></a>Y[R1] &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="kw">sum</span>(R1),<span class="dv">1</span>,<span class="fl">0.75</span>)</span>
<span id="cb240-12"><a href="dondes.html#cb240-12"></a>Y[R2] &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="kw">sum</span>(R2),<span class="dv">1</span>,<span class="fl">0.75</span>)</span>
<span id="cb240-13"><a href="dondes.html#cb240-13"></a>Y[R3] &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="kw">sum</span>(R3),<span class="dv">1</span>,<span class="fl">0.25</span>)</span>
<span id="cb240-14"><a href="dondes.html#cb240-14"></a>df1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(X1,X2,Y)</span>
<span id="cb240-15"><a href="dondes.html#cb240-15"></a>df1<span class="op">$</span>Y &lt;-<span class="st"> </span><span class="kw">factor</span>(df1<span class="op">$</span>Y)</span>
<span id="cb240-16"><a href="dondes.html#cb240-16"></a>indDY1 &lt;-<span class="st"> </span><span class="kw">which</span>(df1<span class="op">$</span>Y<span class="op">==</span><span class="dv">1</span>)</span>
<span id="cb240-17"><a href="dondes.html#cb240-17"></a>df2 &lt;-<span class="st"> </span>df1[<span class="op">-</span>indDY1[<span class="dv">1</span><span class="op">:</span><span class="dv">400</span>],]</span>
<span id="cb240-18"><a href="dondes.html#cb240-18"></a>df3 &lt;-<span class="st"> </span>df1[<span class="op">-</span>indDY1[<span class="dv">1</span><span class="op">:</span><span class="dv">700</span>],]</span>
<span id="cb240-19"><a href="dondes.html#cb240-19"></a>df1 &lt;-<span class="st"> </span>df1[<span class="kw">sample</span>(<span class="kw">nrow</span>(df1),<span class="dv">1000</span>),]</span>
<span id="cb240-20"><a href="dondes.html#cb240-20"></a>df2 &lt;-<span class="st"> </span>df2[<span class="kw">sample</span>(<span class="kw">nrow</span>(df2),<span class="dv">1000</span>),]</span>
<span id="cb240-21"><a href="dondes.html#cb240-21"></a>df3 &lt;-<span class="st"> </span>df3[<span class="kw">sample</span>(<span class="kw">nrow</span>(df3),<span class="dv">1000</span>),]</span></code></pre></div>
<ol style="list-style-type: decimal">
<li><p>Comparer la distribution de <strong>Y</strong> pour ces trois jeux de données et visualiser les observations.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="dondes.html#cb241-1"></a><span class="kw">summary</span>(df1<span class="op">$</span>Y)</span>
<span id="cb241-2"><a href="dondes.html#cb241-2"></a>  <span class="dv">0</span>   <span class="dv">1</span> </span>
<span id="cb241-3"><a href="dondes.html#cb241-3"></a><span class="dv">559</span> <span class="dv">441</span> </span>
<span id="cb241-4"><a href="dondes.html#cb241-4"></a><span class="kw">summary</span>(df2<span class="op">$</span>Y)</span>
<span id="cb241-5"><a href="dondes.html#cb241-5"></a>  <span class="dv">0</span>   <span class="dv">1</span> </span>
<span id="cb241-6"><a href="dondes.html#cb241-6"></a><span class="dv">692</span> <span class="dv">308</span> </span>
<span id="cb241-7"><a href="dondes.html#cb241-7"></a><span class="kw">summary</span>(df3<span class="op">$</span>Y)</span>
<span id="cb241-8"><a href="dondes.html#cb241-8"></a>  <span class="dv">0</span>   <span class="dv">1</span> </span>
<span id="cb241-9"><a href="dondes.html#cb241-9"></a><span class="dv">842</span> <span class="dv">158</span> </span></code></pre></div>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="dondes.html#cb242-1"></a><span class="kw">ggplot</span>(df1)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>X1,<span class="dt">y=</span>X2,<span class="dt">color=</span>Y)<span class="op">+</span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-372-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="dondes.html#cb243-1"></a><span class="kw">ggplot</span>(df2)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>X1,<span class="dt">y=</span>X2,<span class="dt">color=</span>Y)<span class="op">+</span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-372-2.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="dondes.html#cb244-1"></a><span class="kw">ggplot</span>(df3)<span class="op">+</span><span class="kw">aes</span>(<span class="dt">x=</span>X1,<span class="dt">y=</span>X2,<span class="dt">color=</span>Y)<span class="op">+</span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="TUTO_ML_files/figure-html/unnamed-chunk-372-3.png" width="672" style="display: block; margin: auto;" /></p>
<div class="corR">
<p>
Les trois échantillons sont de même taille. Le groupe 0 est toujours plus important que le groupe 1 mais le déséquilibre est plus prononcé pour l’échantillon 2 et surtout l’échantillon 3.
</p>
</div></li>
<li><p>On sépare ces 3 échantillons en un échantillon d’apprentissage et un échantillon test.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="dondes.html#cb245-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb245-2"><a href="dondes.html#cb245-2"></a>a1 &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(df1),<span class="dt">p=</span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)</span>
<span id="cb245-3"><a href="dondes.html#cb245-3"></a>a2 &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(df2),<span class="dt">p=</span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)</span>
<span id="cb245-4"><a href="dondes.html#cb245-4"></a>a3 &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(df3),<span class="dt">p=</span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)</span>
<span id="cb245-5"><a href="dondes.html#cb245-5"></a>train1 &lt;-<span class="st"> </span>df1[a1<span class="op">$</span>Resample1,]</span>
<span id="cb245-6"><a href="dondes.html#cb245-6"></a>train2 &lt;-<span class="st"> </span>df2[a2<span class="op">$</span>Resample1,]</span>
<span id="cb245-7"><a href="dondes.html#cb245-7"></a>train3 &lt;-<span class="st"> </span>df3[a3<span class="op">$</span>Resample1,]</span>
<span id="cb245-8"><a href="dondes.html#cb245-8"></a>test1 &lt;-<span class="st"> </span>df1[<span class="op">-</span>a1<span class="op">$</span>Resample1,]</span>
<span id="cb245-9"><a href="dondes.html#cb245-9"></a>test2 &lt;-<span class="st"> </span>df2[<span class="op">-</span>a2<span class="op">$</span>Resample1,]</span>
<span id="cb245-10"><a href="dondes.html#cb245-10"></a>test3 &lt;-<span class="st"> </span>df3[<span class="op">-</span>a3<span class="op">$</span>Resample1,]</span></code></pre></div>
<p>Ajuster une forêt aléatoire sur les 3 échantillon d’apprentissage, calculer les labels prédits sur les échantillons tests et estimer les différents indicateurs vus en cours à l’aide de <strong>confusionMatrix</strong>.</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="dondes.html#cb246-1"></a><span class="kw">library</span>(randomForest)</span>
<span id="cb246-2"><a href="dondes.html#cb246-2"></a>rf1 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>train1)</span>
<span id="cb246-3"><a href="dondes.html#cb246-3"></a>rf2 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>train2)</span>
<span id="cb246-4"><a href="dondes.html#cb246-4"></a>rf3 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>train3)</span>
<span id="cb246-5"><a href="dondes.html#cb246-5"></a>p1 &lt;-<span class="st"> </span><span class="kw">predict</span>(rf1,<span class="dt">newdata=</span>test1)</span>
<span id="cb246-6"><a href="dondes.html#cb246-6"></a>p2 &lt;-<span class="st"> </span><span class="kw">predict</span>(rf2,<span class="dt">newdata=</span>test2)</span>
<span id="cb246-7"><a href="dondes.html#cb246-7"></a>p3 &lt;-<span class="st"> </span><span class="kw">predict</span>(rf3,<span class="dt">newdata=</span>test3)</span></code></pre></div>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="dondes.html#cb247-1"></a><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>p1,<span class="dt">reference=</span>test1<span class="op">$</span>Y)</span>
<span id="cb247-2"><a href="dondes.html#cb247-2"></a>Confusion Matrix and Statistics</span>
<span id="cb247-3"><a href="dondes.html#cb247-3"></a></span>
<span id="cb247-4"><a href="dondes.html#cb247-4"></a>          Reference</span>
<span id="cb247-5"><a href="dondes.html#cb247-5"></a>Prediction   <span class="dv">0</span>   <span class="dv">1</span></span>
<span id="cb247-6"><a href="dondes.html#cb247-6"></a>         <span class="dv">0</span> <span class="dv">141</span>  <span class="dv">67</span></span>
<span id="cb247-7"><a href="dondes.html#cb247-7"></a>         <span class="dv">1</span>  <span class="dv">43</span>  <span class="dv">81</span></span>
<span id="cb247-8"><a href="dondes.html#cb247-8"></a></span>
<span id="cb247-9"><a href="dondes.html#cb247-9"></a>               Accuracy <span class="op">:</span><span class="st"> </span><span class="fl">0.6687</span>          </span>
<span id="cb247-10"><a href="dondes.html#cb247-10"></a>                 <span class="dv">95</span>% CI <span class="op">:</span><span class="st"> </span>(<span class="fl">0.6152</span>, <span class="fl">0.7191</span>)</span>
<span id="cb247-11"><a href="dondes.html#cb247-11"></a>    No Information Rate <span class="op">:</span><span class="st"> </span><span class="fl">0.5542</span>          </span>
<span id="cb247-12"><a href="dondes.html#cb247-12"></a>    P<span class="op">-</span>Value [Acc <span class="op">&gt;</span><span class="st"> </span>NIR] <span class="op">:</span><span class="st"> </span><span class="fl">1.385e-05</span>       </span>
<span id="cb247-13"><a href="dondes.html#cb247-13"></a></span>
<span id="cb247-14"><a href="dondes.html#cb247-14"></a>                  Kappa <span class="op">:</span><span class="st"> </span><span class="fl">0.3187</span>          </span>
<span id="cb247-15"><a href="dondes.html#cb247-15"></a></span>
<span id="cb247-16"><a href="dondes.html#cb247-16"></a> Mcnemar<span class="st">&#39;s Test P-Value : 0.02831         </span></span>
<span id="cb247-17"><a href="dondes.html#cb247-17"></a></span>
<span id="cb247-18"><a href="dondes.html#cb247-18"></a><span class="st">            Sensitivity : 0.7663          </span></span>
<span id="cb247-19"><a href="dondes.html#cb247-19"></a><span class="st">            Specificity : 0.5473          </span></span>
<span id="cb247-20"><a href="dondes.html#cb247-20"></a><span class="st">         Pos Pred Value : 0.6779          </span></span>
<span id="cb247-21"><a href="dondes.html#cb247-21"></a><span class="st">         Neg Pred Value : 0.6532          </span></span>
<span id="cb247-22"><a href="dondes.html#cb247-22"></a><span class="st">             Prevalence : 0.5542          </span></span>
<span id="cb247-23"><a href="dondes.html#cb247-23"></a><span class="st">         Detection Rate : 0.4247          </span></span>
<span id="cb247-24"><a href="dondes.html#cb247-24"></a><span class="st">   Detection Prevalence : 0.6265          </span></span>
<span id="cb247-25"><a href="dondes.html#cb247-25"></a><span class="st">      Balanced Accuracy : 0.6568          </span></span>
<span id="cb247-26"><a href="dondes.html#cb247-26"></a></span>
<span id="cb247-27"><a href="dondes.html#cb247-27"></a><span class="st">       &#39;</span>Positive<span class="st">&#39; Class : 0               </span></span>
<span id="cb247-28"><a href="dondes.html#cb247-28"></a></span>
<span id="cb247-29"><a href="dondes.html#cb247-29"></a><span class="st">confusionMatrix(data=p2,reference=test2$Y)</span></span>
<span id="cb247-30"><a href="dondes.html#cb247-30"></a><span class="st">Confusion Matrix and Statistics</span></span>
<span id="cb247-31"><a href="dondes.html#cb247-31"></a></span>
<span id="cb247-32"><a href="dondes.html#cb247-32"></a><span class="st">          Reference</span></span>
<span id="cb247-33"><a href="dondes.html#cb247-33"></a><span class="st">Prediction   0   1</span></span>
<span id="cb247-34"><a href="dondes.html#cb247-34"></a><span class="st">         0 196  48</span></span>
<span id="cb247-35"><a href="dondes.html#cb247-35"></a><span class="st">         1  37  51</span></span>
<span id="cb247-36"><a href="dondes.html#cb247-36"></a></span>
<span id="cb247-37"><a href="dondes.html#cb247-37"></a><span class="st">               Accuracy : 0.744           </span></span>
<span id="cb247-38"><a href="dondes.html#cb247-38"></a><span class="st">                 95% CI : (0.6935, 0.7901)</span></span>
<span id="cb247-39"><a href="dondes.html#cb247-39"></a><span class="st">    No Information Rate : 0.7018          </span></span>
<span id="cb247-40"><a href="dondes.html#cb247-40"></a><span class="st">    P-Value [Acc &gt; NIR] : 0.05113         </span></span>
<span id="cb247-41"><a href="dondes.html#cb247-41"></a></span>
<span id="cb247-42"><a href="dondes.html#cb247-42"></a><span class="st">                  Kappa : 0.3681          </span></span>
<span id="cb247-43"><a href="dondes.html#cb247-43"></a></span>
<span id="cb247-44"><a href="dondes.html#cb247-44"></a><span class="st"> Mcnemar&#39;</span>s Test P<span class="op">-</span>Value <span class="op">:</span><span class="st"> </span><span class="fl">0.27808</span>         </span>
<span id="cb247-45"><a href="dondes.html#cb247-45"></a></span>
<span id="cb247-46"><a href="dondes.html#cb247-46"></a>            Sensitivity <span class="op">:</span><span class="st"> </span><span class="fl">0.8412</span>          </span>
<span id="cb247-47"><a href="dondes.html#cb247-47"></a>            Specificity <span class="op">:</span><span class="st"> </span><span class="fl">0.5152</span>          </span>
<span id="cb247-48"><a href="dondes.html#cb247-48"></a>         Pos Pred Value <span class="op">:</span><span class="st"> </span><span class="fl">0.8033</span>          </span>
<span id="cb247-49"><a href="dondes.html#cb247-49"></a>         Neg Pred Value <span class="op">:</span><span class="st"> </span><span class="fl">0.5795</span>          </span>
<span id="cb247-50"><a href="dondes.html#cb247-50"></a>             Prevalence <span class="op">:</span><span class="st"> </span><span class="fl">0.7018</span>          </span>
<span id="cb247-51"><a href="dondes.html#cb247-51"></a>         Detection Rate <span class="op">:</span><span class="st"> </span><span class="fl">0.5904</span>          </span>
<span id="cb247-52"><a href="dondes.html#cb247-52"></a>   Detection Prevalence <span class="op">:</span><span class="st"> </span><span class="fl">0.7349</span>          </span>
<span id="cb247-53"><a href="dondes.html#cb247-53"></a>      Balanced Accuracy <span class="op">:</span><span class="st"> </span><span class="fl">0.6782</span>          </span>
<span id="cb247-54"><a href="dondes.html#cb247-54"></a></span>
<span id="cb247-55"><a href="dondes.html#cb247-55"></a>       <span class="st">&#39;Positive&#39;</span> Class <span class="op">:</span><span class="st"> </span><span class="dv">0</span>               </span>
<span id="cb247-56"><a href="dondes.html#cb247-56"></a></span>
<span id="cb247-57"><a href="dondes.html#cb247-57"></a><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>p3,<span class="dt">reference=</span>test3<span class="op">$</span>Y)</span>
<span id="cb247-58"><a href="dondes.html#cb247-58"></a>Confusion Matrix and Statistics</span>
<span id="cb247-59"><a href="dondes.html#cb247-59"></a></span>
<span id="cb247-60"><a href="dondes.html#cb247-60"></a>          Reference</span>
<span id="cb247-61"><a href="dondes.html#cb247-61"></a>Prediction   <span class="dv">0</span>   <span class="dv">1</span></span>
<span id="cb247-62"><a href="dondes.html#cb247-62"></a>         <span class="dv">0</span> <span class="dv">253</span>  <span class="dv">47</span></span>
<span id="cb247-63"><a href="dondes.html#cb247-63"></a>         <span class="dv">1</span>  <span class="dv">21</span>  <span class="dv">11</span></span>
<span id="cb247-64"><a href="dondes.html#cb247-64"></a></span>
<span id="cb247-65"><a href="dondes.html#cb247-65"></a>               Accuracy <span class="op">:</span><span class="st"> </span><span class="fl">0.7952</span>          </span>
<span id="cb247-66"><a href="dondes.html#cb247-66"></a>                 <span class="dv">95</span>% CI <span class="op">:</span><span class="st"> </span>(<span class="fl">0.7477</span>, <span class="fl">0.8373</span>)</span>
<span id="cb247-67"><a href="dondes.html#cb247-67"></a>    No Information Rate <span class="op">:</span><span class="st"> </span><span class="fl">0.8253</span>          </span>
<span id="cb247-68"><a href="dondes.html#cb247-68"></a>    P<span class="op">-</span>Value [Acc <span class="op">&gt;</span><span class="st"> </span>NIR] <span class="op">:</span><span class="st"> </span><span class="fl">0.933101</span>        </span>
<span id="cb247-69"><a href="dondes.html#cb247-69"></a></span>
<span id="cb247-70"><a href="dondes.html#cb247-70"></a>                  Kappa <span class="op">:</span><span class="st"> </span><span class="fl">0.1373</span>          </span>
<span id="cb247-71"><a href="dondes.html#cb247-71"></a></span>
<span id="cb247-72"><a href="dondes.html#cb247-72"></a> Mcnemar<span class="st">&#39;s Test P-Value : 0.002432        </span></span>
<span id="cb247-73"><a href="dondes.html#cb247-73"></a></span>
<span id="cb247-74"><a href="dondes.html#cb247-74"></a><span class="st">            Sensitivity : 0.9234          </span></span>
<span id="cb247-75"><a href="dondes.html#cb247-75"></a><span class="st">            Specificity : 0.1897          </span></span>
<span id="cb247-76"><a href="dondes.html#cb247-76"></a><span class="st">         Pos Pred Value : 0.8433          </span></span>
<span id="cb247-77"><a href="dondes.html#cb247-77"></a><span class="st">         Neg Pred Value : 0.3438          </span></span>
<span id="cb247-78"><a href="dondes.html#cb247-78"></a><span class="st">             Prevalence : 0.8253          </span></span>
<span id="cb247-79"><a href="dondes.html#cb247-79"></a><span class="st">         Detection Rate : 0.7620          </span></span>
<span id="cb247-80"><a href="dondes.html#cb247-80"></a><span class="st">   Detection Prevalence : 0.9036          </span></span>
<span id="cb247-81"><a href="dondes.html#cb247-81"></a><span class="st">      Balanced Accuracy : 0.5565          </span></span>
<span id="cb247-82"><a href="dondes.html#cb247-82"></a></span>
<span id="cb247-83"><a href="dondes.html#cb247-83"></a><span class="st">       &#39;</span>Positive<span class="st">&#39; Class : 0               </span></span></code></pre></div>
<div class="corR">
<p>
On remarque que l’accuracy est meilleur pour le 3ème échantillon, contrairement à des indicateurs tels que le <span class="math inline"><span class="math inline">\(\kappa\)</span></span> de Cohen ou le <strong>balanced accuracy</strong>.
</p>
</div></li>
<li><p>On considère uniquement l’échantillon <strong>df3</strong>. Refaire l’analyse précédente en utilisant des techniques de ré-échantillonnage.</p>
<div class="corR">
<p>
Le ré-équilibrage doit porter <strong>uniquement</strong> sur l’échantillon d’apprentissage. On propose d’utiliser le radom oversampling, smote, le random undersampling et tomek.
</p>
</div>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="dondes.html#cb248-1"></a>train3.under &lt;-<span class="st"> </span><span class="kw">RandUnderClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>train3)</span>
<span id="cb248-2"><a href="dondes.html#cb248-2"></a>train3.over &lt;-<span class="st"> </span><span class="kw">RandOverClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>train3)</span>
<span id="cb248-3"><a href="dondes.html#cb248-3"></a>train3.smote &lt;-<span class="st"> </span><span class="kw">SmoteClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>train3)</span>
<span id="cb248-4"><a href="dondes.html#cb248-4"></a>train3.tomek &lt;-<span class="st"> </span><span class="kw">TomekClassif</span>(Y<span class="op">~</span>.,<span class="dt">dat=</span>train3)[[<span class="dv">1</span>]]</span></code></pre></div>
<div class="corR">
<p>
On entraîne les forêts aléatoires sur ces nouveaux échantillons et on prédit les individus de l’échantillon test
</p>
</div>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="dondes.html#cb249-1"></a>rf3.under &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>train3.under)</span>
<span id="cb249-2"><a href="dondes.html#cb249-2"></a>rf3.over &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>train3.over)</span>
<span id="cb249-3"><a href="dondes.html#cb249-3"></a>rf3.smote &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>train3.smote)</span>
<span id="cb249-4"><a href="dondes.html#cb249-4"></a>rf3.tomek &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>train3.tomek)</span>
<span id="cb249-5"><a href="dondes.html#cb249-5"></a>p3.under &lt;-<span class="st"> </span><span class="kw">predict</span>(rf3.under,<span class="dt">newdata=</span>test3)</span>
<span id="cb249-6"><a href="dondes.html#cb249-6"></a>p3.over &lt;-<span class="st"> </span><span class="kw">predict</span>(rf3.over,<span class="dt">newdata=</span>test3)</span>
<span id="cb249-7"><a href="dondes.html#cb249-7"></a>p3.smote &lt;-<span class="st"> </span><span class="kw">predict</span>(rf3.smote,<span class="dt">newdata=</span>test3)</span>
<span id="cb249-8"><a href="dondes.html#cb249-8"></a>p3.tomek &lt;-<span class="st"> </span><span class="kw">predict</span>(rf3.tomek,<span class="dt">newdata=</span>test3)</span>
<span id="cb249-9"><a href="dondes.html#cb249-9"></a>mat_prev &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">aucun=</span>p3,<span class="dt">under=</span>p3.under,<span class="dt">over=</span>p3.over,<span class="dt">smote=</span>p3.smote,<span class="dt">tomek=</span>p3.tomek,<span class="dt">obs=</span>test3<span class="op">$</span>Y)</span></code></pre></div>
<div class="corR">
<p>
On en déduit les critères
</p>
</div>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="dondes.html#cb250-1"></a>monba &lt;-<span class="st"> </span><span class="cf">function</span>(prev,obs){<span class="kw">confusionMatrix</span>(prev,obs,<span class="dt">positive=</span><span class="st">&quot;1&quot;</span>)<span class="op">$</span>byClass[<span class="dv">11</span>]}</span>
<span id="cb250-2"><a href="dondes.html#cb250-2"></a>monF1 &lt;-<span class="st"> </span><span class="cf">function</span>(prev,obs){<span class="kw">confusionMatrix</span>(prev,obs,<span class="dt">positive=</span><span class="st">&quot;1&quot;</span>)<span class="op">$</span>byClass[<span class="dv">7</span>]}</span>
<span id="cb250-3"><a href="dondes.html#cb250-3"></a>monkappa &lt;-<span class="st"> </span><span class="cf">function</span>(prev,obs){<span class="kw">confusionMatrix</span>(prev,obs,<span class="dt">positive=</span><span class="st">&quot;1&quot;</span>)<span class="op">$</span>overall[<span class="dv">2</span>]}</span>
<span id="cb250-4"><a href="dondes.html#cb250-4"></a></span>
<span id="cb250-5"><a href="dondes.html#cb250-5"></a>mat_prev <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="op">-</span>obs,<span class="dt">names_to=</span><span class="st">&quot;method&quot;</span>,<span class="dt">values_to=</span><span class="st">&quot;prev&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(method,<span class="dt">.add=</span><span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb250-6"><a href="dondes.html#cb250-6"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">Acc=</span><span class="kw">mean</span>(obs<span class="op">==</span>prev),<span class="dt">BA=</span><span class="kw">monba</span>(prev,obs),<span class="dt">F1=</span><span class="kw">monF1</span>(prev,obs),<span class="dt">kapp=</span><span class="kw">monkappa</span>(prev,obs),<span class="dt">.groups=</span><span class="st">&quot;keep&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb250-7"><a href="dondes.html#cb250-7"></a><span class="st">  </span><span class="kw">summarize_all</span>(<span class="op">~</span><span class="kw">round</span>(.,<span class="dv">3</span>))</span>
<span id="cb250-8"><a href="dondes.html#cb250-8"></a><span class="co"># A tibble: 5 x 5</span></span>
<span id="cb250-9"><a href="dondes.html#cb250-9"></a>  method   Acc    BA    F1  kapp</span>
<span id="cb250-10"><a href="dondes.html#cb250-10"></a>  <span class="op">&lt;</span>chr<span class="op">&gt;</span><span class="st">  </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span><span class="st"> </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span><span class="st"> </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span><span class="st"> </span><span class="er">&lt;</span>dbl<span class="op">&gt;</span></span>
<span id="cb250-11"><a href="dondes.html#cb250-11"></a><span class="dv">1</span> aucun  <span class="fl">0.795</span> <span class="fl">0.557</span> <span class="fl">0.244</span> <span class="fl">0.137</span></span>
<span id="cb250-12"><a href="dondes.html#cb250-12"></a><span class="dv">2</span> over   <span class="fl">0.792</span> <span class="fl">0.629</span> <span class="fl">0.389</span> <span class="fl">0.264</span></span>
<span id="cb250-13"><a href="dondes.html#cb250-13"></a><span class="dv">3</span> smote  <span class="fl">0.699</span> <span class="fl">0.634</span> <span class="fl">0.383</span> <span class="fl">0.204</span></span>
<span id="cb250-14"><a href="dondes.html#cb250-14"></a><span class="dv">4</span> tomek  <span class="fl">0.819</span> <span class="fl">0.564</span> <span class="fl">0.25</span>  <span class="fl">0.17</span> </span>
<span id="cb250-15"><a href="dondes.html#cb250-15"></a><span class="dv">5</span> under  <span class="fl">0.675</span> <span class="fl">0.687</span> <span class="fl">0.432</span> <span class="fl">0.249</span></span></code></pre></div>
<div class="corR">
<p>
L’accuracy est sans surprise meilleur lorsqu’on ne ré-équilibre pas. Cependant les méthodes de ré-équilibrage permettent ici d’améliorer (plus ou moins) les autres critères.
</p>
</div></li>
</ol>
</div>
<div id="exercices-supplémentaires" class="section level2">
<h2><span class="header-section-number">7.3</span> Exercices supplémentaires</h2>

<div class="exercise">
<span id="exr:exo-dondes-echret" class="exercise"><strong>Exercice 7.3  (Echantillonnage rétrospectif)  </strong></span>
</div>

<p>Dans le cadre de l’échantillonnage rétrospectif pour le modèle logistique vu en cours, démontrer la propriété qui lie le modèle logistique initial au modèle ré-équilibré.</p>
<div class="correction">
<p>
On a <span class="math display"><span class="math display">\[\text{logit}\, p_\beta(x_i)=\log\frac{\mathbf P(y_i=1)}{\mathbf P(y_i=0)}\quad\text{et}\quad \text{logit}\, p_\gamma(x_i)=\log\frac{\mathbf P(y_i=1|s_i=1)}{\mathbf P(y_i=0|s_i=1)}.\]</span></span> Or <span class="math display"><span class="math display">\[\mathbf P(y_i=1|s_i=1)=\frac{\mathbf P(y_i=1,s_i=1)}{\mathbf P(s_i=1)}=\frac{\mathbf P(s_i=1|y_i=1)\mathbf P(y_i=1)}{\mathbf P(s_i=1)}\]</span></span> et <span class="math display"><span class="math display">\[\mathbf P(y_i=0|s_i=1)=\frac{\mathbf P(y_i=0,s_i=1)}{\mathbf P(s_i=1)}=\frac{\mathbf P(s_i=1|y_i=0)\mathbf P(y_i=0)}{\mathbf P(s_i=1)}.\]</span></span> Donc <span class="math display"><span class="math display">\[\text{logit}\, p_\gamma(x_i)=\log\frac{\mathbf P(y_i=1)}{\mathbf P(y_i=0)}+\log\frac{\mathbf P(s_i=1|y_i=1)}{\mathbf P(s_i=1|y_i=0)}=\text{logit}\,p_\beta(x_i)+\log\left(\frac{\tau_{1}}{\tau_{0}}\right).\]</span></span>
</p>
</div>

<div class="exercise">
<span id="exr:exo-dondes-cas-temoins" class="exercise"><strong>Exercice 7.4  (Echantillonnage rétrospectif)  </strong></span>
</div>

<p>Une étude cas/témoins est réalisée pour mesurer l’effet du tabac sur une pathologie. Pour ce faire, on choisit <span class="math inline">\(n_1=250\)</span> patients atteints de la pathologie (cas) et <span class="math inline">\(n_0=250\)</span> patients sains (témoins). Les résultats de l’étude sont présentés ci-dessous</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">Fumeur</th>
<th align="center">Non fumeur</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Non malade</td>
<td align="center">48</td>
<td align="center">202</td>
</tr>
<tr class="even">
<td align="center">Malade</td>
<td align="center">208</td>
<td align="center">42</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li><p>A partir des données obtenues, estimer à l’aide d’un modèle logistique la probabilité d’être atteint pour un fumeur, puis pour un non fumeur.</p>
<div class="corR">
<p>
Pour simplifier on va construire un jeu de données qui correspond au résultat :
</p>
</div>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="dondes.html#cb251-1"></a>X&lt;-<span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">500</span>)</span>
<span id="cb251-2"><a href="dondes.html#cb251-2"></a>X[<span class="dv">1</span><span class="op">:</span><span class="dv">256</span>]&lt;-<span class="st">&quot;fumeur&quot;</span></span>
<span id="cb251-3"><a href="dondes.html#cb251-3"></a>X[<span class="dv">257</span><span class="op">:</span><span class="dv">500</span>]&lt;-<span class="st">&quot;non_fumeur&quot;</span></span>
<span id="cb251-4"><a href="dondes.html#cb251-4"></a>Y&lt;-<span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">500</span>)</span>
<span id="cb251-5"><a href="dondes.html#cb251-5"></a>Y[<span class="dv">1</span><span class="op">:</span><span class="dv">48</span>]&lt;-<span class="dv">0</span></span>
<span id="cb251-6"><a href="dondes.html#cb251-6"></a>Y[<span class="dv">257</span><span class="op">:</span><span class="dv">458</span>]&lt;-<span class="dv">0</span></span>
<span id="cb251-7"><a href="dondes.html#cb251-7"></a>Y&lt;-<span class="kw">factor</span>(Y)</span>
<span id="cb251-8"><a href="dondes.html#cb251-8"></a>X&lt;-<span class="kw">factor</span>(X)</span>
<span id="cb251-9"><a href="dondes.html#cb251-9"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Y,X)</span>
<span id="cb251-10"><a href="dondes.html#cb251-10"></a>model&lt;-<span class="kw">glm</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>df,<span class="dt">family=</span>binomial)</span></code></pre></div>
<div class="corR">
<p>
On peut maintenant estimer le modèle logistique et obtenir les prévisions demandées :
</p>
</div>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="dondes.html#cb252-1"></a>newX &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">X=</span><span class="kw">c</span>(<span class="st">&quot;fumeur&quot;</span>,<span class="st">&quot;non_fumeur&quot;</span>))</span>
<span id="cb252-2"><a href="dondes.html#cb252-2"></a><span class="kw">predict</span>(model,<span class="dt">newdata=</span>newX,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">3</span>)</span>
<span id="cb252-3"><a href="dondes.html#cb252-3"></a>    <span class="dv">1</span>     <span class="dv">2</span> </span>
<span id="cb252-4"><a href="dondes.html#cb252-4"></a><span class="fl">0.812</span> <span class="fl">0.172</span> </span></code></pre></div></li>
<li><p>Comment interpréter ces deux probabilités ? Est-ce qu’elles estiment la probabilité d’être atteint pour un individu quelconque dans la population ?</p>
<div class="corR">
<p>
Non ! On a échantillonné de manière à avoir autant de patients malades que non malades, ce qui n’est pas vrai dans la population totale. On est face à un biais d’échantillonnage que l’on peut corriger à l’aide de l’exercice précédent.
</p>
</div></li>
<li><p>Des études précédentes ont montré que cinq individus sur mille sont atteints par la pathologie dans la population entière. En utilisant la propriété de l’exercice précédent, en déduire les probabilités d’être atteint pour un fumeur et un non fumeur dans la population.</p>
<div class="corR">
<p>
On rappelle que <span class="math display"><span class="math display">\[\tau_1=\mathbf P(S=1|Y=1)=\frac{\mathbf P(Y=1|S=1)\mathbf P(S=1)}{\mathbf P(Y=1)}.\]</span></span> Comme <span class="math inline"><span class="math inline">\(\mathbf P(Y=1|S=1)=\mathbf P(Y=0|S=1)=1/2\)</span></span>, on déduit <span class="math display"><span class="math display">\[\frac{\tau_1}{\tau_0}=\frac{\mathbf P(Y=0)}{\mathbf P(Y=1)}=\frac{\pi_0}{\pi_1}=\frac{0.005}{0.995}.\]</span></span> On obtient ainsi les probabilités demandées avec
</p>
</div>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="dondes.html#cb253-1"></a>beta&lt;-model<span class="op">$</span>coefficients</span>
<span id="cb253-2"><a href="dondes.html#cb253-2"></a>pi1&lt;-<span class="fl">0.005</span></span>
<span id="cb253-3"><a href="dondes.html#cb253-3"></a>pi0&lt;-<span class="fl">0.995</span></span>
<span id="cb253-4"><a href="dondes.html#cb253-4"></a>beta1_cor &lt;-beta[<span class="dv">1</span>]<span class="op">-</span><span class="kw">log</span>(pi0<span class="op">/</span>pi1)</span>
<span id="cb253-5"><a href="dondes.html#cb253-5"></a></span>
<span id="cb253-6"><a href="dondes.html#cb253-6"></a>p1F &lt;-<span class="st"> </span><span class="kw">exp</span>(beta1_cor)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(beta1_cor))</span>
<span id="cb253-7"><a href="dondes.html#cb253-7"></a>p1NF &lt;-<span class="st"> </span><span class="kw">exp</span>(beta1_cor<span class="op">+</span>beta[<span class="dv">2</span>])<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(beta1_cor<span class="op">+</span>beta[<span class="dv">2</span>]))</span>
<span id="cb253-8"><a href="dondes.html#cb253-8"></a>p1F</span>
<span id="cb253-9"><a href="dondes.html#cb253-9"></a>(Intercept) </span>
<span id="cb253-10"><a href="dondes.html#cb253-10"></a> <span class="fl">0.02131148</span> </span>
<span id="cb253-11"><a href="dondes.html#cb253-11"></a>p1NF</span>
<span id="cb253-12"><a href="dondes.html#cb253-12"></a>(Intercept) </span>
<span id="cb253-13"><a href="dondes.html#cb253-13"></a><span class="fl">0.001043738</span> </span></code></pre></div>
<div class="corR">
<p>
On peut retrouver les paramètres du modèle corrigé en utilisant l’option <code>offset</code>
</p>
</div>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="dondes.html#cb254-1"></a>mod_cor &lt;-<span class="st"> </span><span class="kw">glm</span>(Y<span class="op">~</span>.,<span class="dt">data=</span>df,<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>,<span class="dt">offset =</span> <span class="kw">rep</span>(<span class="kw">log</span>(pi0<span class="op">/</span>pi1),<span class="kw">nrow</span>(df)))</span>
<span id="cb254-2"><a href="dondes.html#cb254-2"></a><span class="kw">coef</span>(mod_cor)</span>
<span id="cb254-3"><a href="dondes.html#cb254-3"></a>(Intercept) Xnon_fumeur </span>
<span id="cb254-4"><a href="dondes.html#cb254-4"></a>  <span class="fl">-3.826968</span>   <span class="fl">-3.036935</span> </span>
<span id="cb254-5"><a href="dondes.html#cb254-5"></a><span class="kw">c</span>(beta1_cor,beta[<span class="dv">2</span>])</span>
<span id="cb254-6"><a href="dondes.html#cb254-6"></a>(Intercept) Xnon_fumeur </span>
<span id="cb254-7"><a href="dondes.html#cb254-7"></a>  <span class="fl">-3.826968</span>   <span class="fl">-3.036935</span> </span></code></pre></div></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="deep.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comp-algo.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TUTO_ML.pdf"],
"toc": {
"collapse": "subsection",
"sharing": {
"facebook": true,
"github": true,
"twitter": true
}
},
"highlight": "tango"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
